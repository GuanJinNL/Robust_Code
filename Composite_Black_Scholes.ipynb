{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23c2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "import mosek\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "import scipy.stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import weibull_min\n",
    "import cyipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bcc8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlog_exp(x,a,b):\n",
    "    if x > 0 :\n",
    "        e = np.exp(1)\n",
    "        c1 = b**2*(a**2+a)*np.exp(a-1)\n",
    "        c2 = c1 - np.exp(a)*(a*b+1)\n",
    "        c3 = np.exp(a+1)\n",
    "        term1 = (x+e)*np.exp(a*np.log(x+e)**b) \n",
    "        print(1/c1,c2/c1,-c3/c1)\n",
    "        return(1/c1*(term1 +c2*x-c3))\n",
    "    else:\n",
    "        return(np.exp(x)-1)\n",
    "    \n",
    "def dlog_exp(x,a,b):\n",
    "    if x > 0:\n",
    "        e = np.exp(1)\n",
    "        c1 = b**2*(a**2+a)*np.exp(a-1)\n",
    "        c2 = c1 - np.exp(a)*(a*b+1)\n",
    "        term1 = np.exp(a*np.log(x+e)**b)*(a*b*np.log(x+e)**(b-1)+1)\n",
    "        return((1/c1)*(term1+c2))\n",
    "    else:\n",
    "        return(np.exp(x))\n",
    "def ddlog_exp(x,a,b):\n",
    "    if x > 0:\n",
    "        e = np.exp(1)\n",
    "        c1 = b**2*(a**2+a)*np.exp(a-1)\n",
    "        c2 = c1 - np.exp(a)*(a*b+1)\n",
    "        term1 = a*b*(np.log(x+e))**b+b+np.log(x+e)-1\n",
    "        term2 = a*b*np.exp(a*(np.log(x+e))**b)*(np.log(x+e))**(b-2)\n",
    "        return((1/c1)*(term1*term2/(x+e)))\n",
    "    else:\n",
    "        return(np.exp(x))\n",
    "def d1dl(t1,s_vec,lbda,a,b,N):\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        fac1 = -(s_vec[i]+t1)/(lbda**2)\n",
    "        fac2 = 1/N*ddlog_exp((s_vec[i]+t1)/lbda,a,b)\n",
    "        som = som + fac1*fac2 \n",
    "    return(som)\n",
    "\n",
    "def d1ds(t1,s,lbda,a,b,N):\n",
    "    return(1/N*ddlog_exp((s+t1)/lbda,a,b)*1/lbda)\n",
    "\n",
    "def dsdl(t1,s,lbda,a,b,N):\n",
    "    return(1/N*(-s-t1)/(lbda**2)*ddlog_exp((s+t1)/lbda,a,b))\n",
    "\n",
    "def dl2(t1,s_vec,lbda,a,b,N):\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        som = som + (s_vec[i]+t1)**2/(lbda**3)*ddlog_exp((s_vec[i]+t1)/lbda,a,b)\n",
    "    return(som/N)\n",
    "\n",
    "def dt_12(t1,s_vec,lbda,a,b,N):\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        som = som + ddlog_exp((s_vec[i]+t1)/lbda,a,b)/lbda\n",
    "    return(som/N)\n",
    "def ds2(t1,s,lbda,a,b,N):\n",
    "    return(1/N*ddlog_exp((s+t1)/lbda,a,b)*1/lbda)\n",
    "    \n",
    "def cvar_conj(x,alpha):\n",
    "    return(np.maximum(1/alpha*x,0))\n",
    "    #return(1/alpha *x)\n",
    "\n",
    "def dcvar_conj(x,alpha):\n",
    "    if x>0:\n",
    "        return(1/alpha)\n",
    "    else:\n",
    "        return(0)\n",
    "    #return(1/alpha)\n",
    "\n",
    "def q_wc(x,the1, the2,lbda,a,b,alpha):\n",
    "    arg = (cvar_conj((the2-x),alpha)+the1)/lbda\n",
    "    return(dlog_exp(arg,a,b))\n",
    "\n",
    "def qb_wc(x,the1, the2,lbda,a,b,alpha):\n",
    "    arg = q_wc(x,the1, the2,lbda,a,b,alpha)\n",
    "    return(arg*dcvar_conj(the2-x,alpha))\n",
    "    \n",
    "def qqb_wc(x,the1, the2,lbda,a,b,alpha):\n",
    "    term1 = (the1 + cvar_conj(the2-x,alpha))/lbda\n",
    "    term2 = q_wc(x,the1, the2,lbda,a,b,alpha)\n",
    "    term3 = xlog_exp(term1,a,b)\n",
    "    return(term1*term2-term3)\n",
    "\n",
    "def fvalue (x,*data):\n",
    "    X,a,b,alpha,r = data\n",
    "    the1 = x[0]\n",
    "    the2 = x[1]\n",
    "    lbda = x[2]\n",
    "    N = len(X)\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    s3 = 0\n",
    "    for i in range(N):\n",
    "        s1 = s1 + q_wc(X[i],the1, the2,lbda,a,b,alpha)\n",
    "        s2 = s2 + qb_wc(X[i],the1, the2,lbda,a,b,alpha)\n",
    "        s3 = s3 + qqb_wc(X[i],the1, the2,lbda,a,b,alpha)\n",
    "    return(s1/N-1,s2/N-1,s3/N-r)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0292de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.590007070811249 -6.413495895797396 -16.79330931575148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10499006056507311"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlog_exp(0.1, 0.1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58fdc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d1(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term1 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + 1/N * dlog_exp((term1+t1)/lbda,a,b)\n",
    "    return(-1+som)\n",
    "\n",
    "def d2(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term1 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + 1/N* dlog_exp((term1+t1)/lbda,a,b)*dcvar_conj(t2-X[i],alpha)\n",
    "    return(-1+som)\n",
    "\n",
    "def dl(t1,t2,lbda,a,b,r,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        arg = (term0+t1)/lbda\n",
    "        term1 = xlog_exp(arg,a,b) - dlog_exp(arg,a,b)*arg\n",
    "        som = som + 1/N* term1\n",
    "    return(r+som)\n",
    "\n",
    "def d11(t1,t2,lbda,a,b,alpha,X):\n",
    "    som = 0\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + ddlog_exp((term0 + t1)/lbda,a,b)/lbda\n",
    "    return(som/N)\n",
    "\n",
    "def d12(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + ddlog_exp((term0 + t1)/lbda,a,b)/lbda*dcvar_conj(t2-X[i],alpha)\n",
    "    return(som/N)\n",
    "\n",
    "def d1l(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        fac1 = -(term0+t1)/(lbda**2)\n",
    "        fac2 = 1/N*ddlog_exp((term0+t1)/lbda,a,b)\n",
    "        som = som + fac1*fac2 \n",
    "    return(som/N)\n",
    "\n",
    "def d22(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + ddlog_exp((term0 + t1)/lbda,a,b)/lbda *1/alpha*dcvar_conj(t2-X[i],alpha)\n",
    "    return(som/N)\n",
    "\n",
    "def d2l(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + ddlog_exp((term0 + t1)/lbda,a,b)*(-(term0+t1)/lbda**2)*dcvar_conj(t2-X[i],alpha)\n",
    "    return(som/N)\n",
    "\n",
    "def dll(t1,t2,lbda,a,b,alpha,X):\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        term0 = cvar_conj(t2-X[i],alpha)\n",
    "        som = som + (term0+t1)**2/(lbda**3)*ddlog_exp((term0+t1)/lbda,a,b)\n",
    "    return(som/N)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d902e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.025\u001b[39m\n\u001b[0;32m      5\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m\n\u001b[1;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m (X, a,b,alpha,r)\n\u001b[0;32m      7\u001b[0m initial_guess \u001b[38;5;241m=\u001b[39m z  \u001b[38;5;66;03m# Initial guess for the root\u001b[39;00m\n\u001b[0;32m      8\u001b[0m fsolve(fvalue, initial_guess, args\u001b[38;5;241m=\u001b[39mdata, full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "a = 0.001\n",
    "b = 2\n",
    "alpha = 0.025\n",
    "r = 0.001\n",
    "data = (X, a,b,alpha,r)\n",
    "initial_guess = z  # Initial guess for the root\n",
    "fsolve(fvalue, initial_guess, args=data, full_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2db0afa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00020008230242019032, -1.0, -0.0009999799834577712)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fvalue (z,*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5d9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "X = -(np.random.lognormal(0,1,size= 5))\n",
    "a = 0.01\n",
    "b = 2\n",
    "alpha = 0.5\n",
    "r = 0.1\n",
    "para = [a,b,alpha,r]\n",
    "f = np.zeros(len(X)) + 1/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9f58686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.9812434 , -1.54729748, -1.10130679, -0.15512986, -0.75776028,\n",
       "       -0.70134246, -0.92058911, -0.53419161, -0.95712798, -0.62050723,\n",
       "       -0.26877928, -2.4220696 , -2.41407947, -5.52660147, -1.05130646,\n",
       "       -0.667192  , -0.57963311, -0.21299697, -2.67077164, -0.33251589,\n",
       "       -0.30573195, -0.81411805, -4.42003827, -1.26708155, -0.35923262,\n",
       "       -0.49017481, -1.86870367, -0.85170644, -0.46355217, -0.79450919,\n",
       "       -2.10655996, -7.21462909, -0.28819345, -0.53450355, -0.44763993,\n",
       "       -0.08900318, -0.39701071, -0.35920007, -3.07707035, -0.87641616])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "412d512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_cvar_ball(alpha,x,f,r):\n",
    "    n = len(x)\n",
    "    theta_1 = cp.Variable(1)\n",
    "    theta_2 = cp.Variable(1)\n",
    "    lbda = cp.Variable(1, nonneg = True)\n",
    "    t = cp.Variable(n)\n",
    "    w = cp.Variable(n)\n",
    "    s = cp.Variable(n)\n",
    "    constraints = []\n",
    "    som = 0\n",
    "    for i in range(n):\n",
    "        #if wbln_factor(-x[i],0,np.sqrt(1.5)) >= 1e-5:\n",
    "        constraints.append(theta_1 + cp.pos(1/alpha*(theta_2-x[i])) <= s[i])\n",
    "        constraints.append((w[i] - lbda) <= t[i])   #2/(-x[i])*\n",
    "        constraints.append(cp.kl_div(lbda,w[i])+lbda+s[i]-w[i]<= 0)\n",
    "        som = som + t[i]*f[i]\n",
    "    obj = cp.Minimize(-theta_1-theta_2+lbda*r+som)\n",
    "    prob = cp.Problem(obj,constraints)\n",
    "    prob.solve(solver = cp.MOSEK)\n",
    "    return(prob.value, theta_1.value, theta_2.value, lbda.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264f9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[obj,x_s1, x_s2, x_s3] = kl_cvar_ball(alpha,X,f,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7858d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0519835394916175 [-2.58237859] [-1.5472973] [9.22932021]\n"
     ]
    }
   ],
   "source": [
    "print(obj, x_s1,x_s2,x_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "33dcb55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.9812434 , -1.54729748])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46e24e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b7f02bfe10>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10,20,0.01)\n",
    "y = np.zeros(len(x))\n",
    "for i in range(len(x)):\n",
    "    y[i] = ddlog_exp(x[i],a,b)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5daad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Ipopt with dummy variables\n",
    "\n",
    "\n",
    "class HS071():\n",
    "    \n",
    "    def __init__(self, X, para):\n",
    "        self.X = X  # Store X as an instance attribute\n",
    "        self.para = para\n",
    "\n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(x)-3\n",
    "        som = 0\n",
    "        for i in range(3,len(x)):\n",
    "            som = som + lbda * xlog_exp((x[i]+the1)/lbda,a,b)\n",
    "        som = som/N - the1 -the2 + lbda*r\n",
    "        return(som)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(x)-3\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        grad = np.zeros(len(x))\n",
    "        grad[1] = -1  \n",
    "        for i in range(3,len(x)):\n",
    "            grad[i] = dlog_exp((x[i]+the1)/lbda,a,b)/N\n",
    "            s1 = s1 + dlog_exp((x[i]+the1)/lbda,a,b)/N\n",
    "            s2 = s2 + xlog_exp((x[i]+the1)/lbda,a,b)/N - dlog_exp((x[i]+the1)/lbda,a,b)/N * ((x[i]+the1)/lbda)\n",
    "        grad[0] = -1 + s1\n",
    "        grad[2] = r + s2\n",
    "        return(grad)\n",
    "             \n",
    "        \n",
    "       \n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        N = len(self.X)\n",
    "        cons = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            cons[i] = 1/alpha * (x[1]-self.X[i])-x[i+3] \n",
    "        \n",
    "        return(cons)\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        N = len(self.X)\n",
    "        jacob = np.zeros(len(x))\n",
    "        jacob[1] = 1/alpha\n",
    "        for i in range(3,len(x)):\n",
    "            jacob[i] = -1\n",
    "        jacob = np.array([jacob])\n",
    "        \n",
    "        row, col = self.jacobianstructure()\n",
    "        return(jacob[row,col])\n",
    "    def jacobianstructure(self):\n",
    "        N = len(self.X)\n",
    "        jac_struc = np.zeros(N+3)+1\n",
    "        jac_struc[0] = 0\n",
    "        jac_struc[2] = 0\n",
    "        jac_struc = np.array([jac_struc])\n",
    "        return(np.nonzero(jac_struc))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "        a,b,alpha,r = self.para\n",
    "        N = len(self.X)\n",
    "        struc = np.tril(np.ones((N+3,N+3)))\n",
    "        struc[1,:] = 0\n",
    "        struc[0:N+3,1] = 0\n",
    "        for i in range(3,N+1):\n",
    "            struc[(i+1):(N+3),i] = 0\n",
    "        struc[N+2,N+1] = 0\n",
    "        return np.nonzero(struc)\n",
    "\n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        N = len(self.X)\n",
    "        H = np.zeros((N+3,N+3))\n",
    "        s_vec = x[3:len(x)]\n",
    "        t1 = x[0]\n",
    "        t2 = x[1]\n",
    "        lbda = x[2]\n",
    "        H[0,0] = dt_12(t1,s_vec,lbda,a,b,N)\n",
    "        H[2,0] = d1dl(t1,s_vec,lbda,a,b,N)\n",
    "        H[2,2] = dl2(t1,s_vec,lbda,a,b,N)\n",
    "        for i in range(3,len(x)):\n",
    "            H[i,0] = d1ds(t1,x[i],lbda,a,b,N)\n",
    "            H[i,2] = dsdl(t1,x[i],lbda,a,b,N)\n",
    "            H[i,i] = ds2(t1,x[i],lbda,a,b,N)\n",
    "\n",
    "        H = obj_factor*H\n",
    "\n",
    "        row, col = self.hessianstructure()\n",
    "\n",
    "        return H[row, col]\n",
    "\n",
    "\n",
    "    def intermediate(self, alg_mod, iter_count, obj_value, inf_pr, inf_du, mu,\n",
    "                     d_norm, regularization_size, alpha_du, alpha_pr,\n",
    "                     ls_trials):\n",
    "        \"\"\"Prints information at every Ipopt iteration.\"\"\"\n",
    "\n",
    "        msg = \"Objective value at iteration #{:d} is - {:g}\"\n",
    "\n",
    "        print(msg.format(iter_count, obj_value))\n",
    "        print(iter_count, inf_pr)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6cec25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Ipopt without dummy variables\n",
    "\n",
    "\n",
    "class HS072():\n",
    "    \n",
    "    def __init__(self, X, para):\n",
    "        self.X = X  # Store X as an instance attribute\n",
    "        self.para = para\n",
    "\n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        t1 = x[0]\n",
    "        t2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(self.X)\n",
    "        som = 0\n",
    "        for i in range(N):\n",
    "            term0 = cvar_conj(t2-self.X[i],alpha)\n",
    "            som = som + lbda * xlog_exp((term0 + t1)/lbda,a,b)\n",
    "        som = som/N - t1 -t2 + lbda*r\n",
    "        return(som)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        t1 = x[0]\n",
    "        t2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(self.X)\n",
    "        grad = np.zeros(3)\n",
    "        grad[0] = d1(t1,t2,lbda,a,b,alpha,self.X)\n",
    "        grad[1] = d2(t1,t2,lbda,a,b,alpha,self.X)\n",
    "        grad[2] = dl(t1,t2,lbda,a,b,r,alpha,self.X)\n",
    "        return(grad)\n",
    "             \n",
    "        \n",
    "       \n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        cons = 1/2 *(x[0]**2 + x[1]**2 + x[2]**2)\n",
    "        return(cons)\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        return(x) \n",
    "    \n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "        return np.nonzero(np.tril(np.ones((3,3))))\n",
    "\n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"\n",
    "        a,b,alpha,r = self.para\n",
    "        N = len(self.X)\n",
    "        H = np.zeros((3,3))\n",
    "        t1 = x[0]\n",
    "        t2 = x[1]\n",
    "        lbda = x[2]\n",
    "        H[0,0] = d11(t1,t2,lbda,a,b,alpha,self.X) * obj_factor + lagrange[0]\n",
    "        H[1,0] = d12(t1,t2,lbda,a,b,alpha,self.X) * obj_factor\n",
    "        H[2,0] = d1l(t1,t2,lbda,a,b,alpha,self.X) * obj_factor\n",
    "        H[1,1] = d22(t1,t2,lbda,a,b,alpha,self.X) * obj_factor + lagrange[0]\n",
    "        H[1,2] = d2l(t1,t2,lbda,a,b,alpha,self.X) * obj_factor\n",
    "        H[2,2] = dll(t1,t2,lbda,a,b,alpha,self.X) * obj_factor + lagrange[0]\n",
    "\n",
    "        row, col = self.hessianstructure()\n",
    "\n",
    "        return H[row, col]\n",
    "\n",
    "\n",
    "    def intermediate(self, alg_mod, iter_count, obj_value, inf_pr, inf_du, mu,\n",
    "                     d_norm, regularization_size, alpha_du, alpha_pr,\n",
    "                     ls_trials):\n",
    "        \"\"\"Prints information at every Ipopt iteration.\"\"\"\n",
    "\n",
    "        msg = \"Objective value at iteration #{:d} is - {:g}\"\n",
    "\n",
    "        print(msg.format(iter_count, obj_value))\n",
    "        print(iter_count, inf_pr)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce301893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HS073(cyipopt.Problem):\n",
    "    \n",
    "    \n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(X)\n",
    "        som = 0\n",
    "        for i in range(3,len(x)):\n",
    "            som = som + lbda * xlog_exp((x[i]+the1)/lbda,a,b)\n",
    "        som = som/N - the1 -the2 + lbda*r\n",
    "        return(som)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(X)\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        grad = np.zeros(len(x))\n",
    "        grad[1] = -1  \n",
    "        for i in range(3,len(x)):\n",
    "            grad[i] = dlog_exp((x[i]+the1)/lbda,a,b)/N\n",
    "            s1 = s1 + dlog_exp((x[i]+the1)/lbda,a,b)/N\n",
    "            s2 = s2 + xlog_exp((x[i]+the1)/lbda,a,b)/N - dlog_exp((x[i]+the1)/lbda,a,b)/N * ((x[i]+the1)/lbda)\n",
    "        grad[0] = -1 + s1\n",
    "        grad[2] = r + s2\n",
    "        return(grad)\n",
    "             \n",
    "        \n",
    "       \n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        cons = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            cons[i] = 1/alpha * (x[1]-X[i])-x[i+3] \n",
    "        \n",
    "        return(cons)\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        jacob = np.zeros(len(x))\n",
    "        jacob[1] = 1/alpha\n",
    "        for i in range(3,len(x)):\n",
    "            jacob[i] = -1\n",
    "        jacob = np.array([jacob])\n",
    "        \n",
    "        row, col = self.jacobianstructure()\n",
    "        return(jacob[row,col])\n",
    "    def jacobianstructure(self):\n",
    "        N = len(X)\n",
    "        jac_struc = np.zeros(N+3)+1\n",
    "        jac_struc[0] = 0\n",
    "        jac_struc[2] = 0\n",
    "        jac_struc = np.array([jac_struc])\n",
    "        return(np.nonzero(jac_struc))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        struc = np.tril(np.ones((N+3,N+3)))\n",
    "        struc[1,:] = 0\n",
    "        struc[0:N+3,1] = 0\n",
    "        for i in range(3,N+1):\n",
    "            struc[(i+1):(N+3),i] = 0\n",
    "        struc[N+2,N+1] = 0\n",
    "        return np.nonzero(struc)\n",
    "\n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        H = np.zeros((N+3,N+3))\n",
    "        s_vec = x[3:len(x)]\n",
    "        t1 = x[0]\n",
    "        t2 = x[1]\n",
    "        lbda = x[2]\n",
    "        H[0,0] = dt_12(t1,s_vec,lbda,a,b,N)\n",
    "        H[2,0] = d1dl(t1,s_vec,lbda,a,b,N)\n",
    "        H[2,2] = dl2(t1,s_vec,lbda,a,b,N)\n",
    "        for i in range(3,len(x)):\n",
    "            H[i,0] = d1ds(t1,x[i],lbda,a,b,N)\n",
    "            H[i,2] = dsdl(t1,x[i],lbda,a,b,N)\n",
    "            H[i,i] = ds2(t1,x[i],lbda,a,b,N)\n",
    "\n",
    "        H = obj_factor*H\n",
    "\n",
    "        row, col = self.hessianstructure()\n",
    "\n",
    "        return H[row, col]\n",
    "\n",
    "\n",
    "    def intermediate(self, alg_mod, iter_count, obj_value, inf_pr, inf_du, mu,\n",
    "                     d_norm, regularization_size, alpha_du, alpha_pr,\n",
    "                     ls_trials):\n",
    "        \"\"\"Prints information at every Ipopt iteration.\"\"\"\n",
    "        iterate = self.get_current_iterate()\n",
    "        infeas = self.get_current_violations()\n",
    "        primal = iterate[\"x\"]\n",
    "        jac = self.jacobian(primal)\n",
    "        msg = \"Objective value at iteration #{:d} is - {:g}\"\n",
    "\n",
    "        print(msg.format(iter_count, obj_value))\n",
    "        print(\"Primal iterate:\", primal[0:5])\n",
    "        infeasi = []\n",
    "        for i in range(len(X)):\n",
    "            infeasi.append(1/alpha * (primal[1]-X[i])-primal[3+i])\n",
    "        print('infeasi:', np.max(infeasi))\n",
    "        print('inf_pr:', inf_pr)\n",
    "        #print(\"Flattened Jacobian:\", jac)\n",
    "        #print(\"Dual infeasibility:\", infeas[\"grad_lag_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0d5c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_c(x):\n",
    "    return(np.exp(x)-1)\n",
    "\n",
    "def d_kl_c(x):\n",
    "    return(np.exp(x))\n",
    "\n",
    "def dd_kl_c(x):\n",
    "    return(np.exp(x))\n",
    "\n",
    "def kl_d1dl(t1,s_vec,lbda,a,b,N):\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        fac1 = -(s_vec[i]+t1)/(lbda**2)\n",
    "        fac2 = 1/N*dd_kl_c((s_vec[i]+t1)/lbda)\n",
    "        som = som + fac1*fac2 \n",
    "    return(som)\n",
    "\n",
    "def kl_d1ds(t1,s,lbda,a,b,N):\n",
    "    return(1/N*dd_kl_c((s+t1)/lbda)*1/lbda)\n",
    "\n",
    "def kl_dsdl(t1,s,lbda,a,b,N):\n",
    "    return(1/N*(-s-t1)/(lbda**2)*dd_kl_c((s+t1)/lbda))\n",
    "\n",
    "def kl_dll(t1,s_vec,lbda,a,b,N):\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        som = som + (s_vec[i]+t1)**2/(lbda**3)*dd_kl_c((s_vec[i]+t1)/lbda)\n",
    "    return(som/N)\n",
    "\n",
    "def kl_d11(t1,s_vec,lbda,a,b,N):\n",
    "    som = 0\n",
    "    for i in range(N):\n",
    "        som = som + dd_kl_c((s_vec[i]+t1)/lbda)/lbda\n",
    "    return(som/N)\n",
    "def kl_dss(t1,s,lbda,a,b,N):\n",
    "    return(1/N*dd_kl_c((s+t1)/lbda)*1/lbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "788fcd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Robust KL-CVaR\n",
    "\n",
    "class HS074(cyipopt.Problem):\n",
    "    \n",
    "    \n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(X)\n",
    "        som = 0\n",
    "        for i in range(3,N+3):\n",
    "            som = som + lbda * kl_c((x[i]+the1)/lbda)\n",
    "        return(-x[0]-x[1]+x[2]*r+som)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(X)\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        grad = np.zeros(N+3)\n",
    "        grad[1] = -1  \n",
    "        for i in range(3,N+3):\n",
    "            grad[i] = d_kl_c((x[i]+the1)/lbda)/N\n",
    "            s1 = s1 + d_kl_c((x[i]+the1)/lbda)/N\n",
    "            s2 = s2 + kl_c((x[i]+the1)/lbda) - d_kl_c((x[i]+the1)/lbda)*((x[i]+the1)/lbda)\n",
    "        grad[0] = -1 + s1\n",
    "        grad[2] = r + s2/N\n",
    "        return(grad)\n",
    "             \n",
    "        \n",
    "       \n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        cons = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            cons[i] = 1/alpha*(x[1]-X[i])-x[i+3] \n",
    "        \n",
    "        return(cons)\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        jacob = np.zeros(N+3)\n",
    "        jacob[1] = 1/alpha\n",
    "        for i in range(3,N+3):\n",
    "            jacob[i] = -1\n",
    "        jacob = np.array([jacob])\n",
    "        \n",
    "        row, col = self.jacobianstructure()\n",
    "        return(jacob[row,col])\n",
    "    def jacobianstructure(self):\n",
    "        N = len(X)\n",
    "        jac_struc = np.zeros(N+3)+1\n",
    "        jac_struc[0] = 0\n",
    "        jac_struc[2] = 0\n",
    "        jac_struc = np.array([jac_struc])\n",
    "        return(np.nonzero(jac_struc))\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        struc = np.tril(np.ones((N+3,N+3)))\n",
    "        struc[1,:] = 0\n",
    "        struc[0:N+3,1] = 0\n",
    "        for i in range(3,N+1):\n",
    "            struc[(i+1):(N+3),i] = 0\n",
    "        struc[N+2,N+1] = 0\n",
    "        return np.nonzero(struc)\n",
    "\n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        H = np.zeros((N+3,N+3))\n",
    "        s_vec = x[3:(N+3)]\n",
    "        t1 = x[0]\n",
    "        t2 = x[1]\n",
    "        lbda = x[2]\n",
    "        H[0,0] = kl_d11(t1,s_vec,lbda,a,b,N)\n",
    "        H[2,0] = kl_d1dl(t1,s_vec,lbda,a,b,N)\n",
    "        H[2,2] = kl_dll(t1,s_vec,lbda,a,b,N)\n",
    "        for i in range(3,N+3):\n",
    "            H[i,0] = kl_d1ds(t1,x[i],lbda,a,b,N)\n",
    "            H[i,2] = kl_dsdl(t1,x[i],lbda,a,b,N)\n",
    "            H[i,i] = kl_dss(t1,x[i],lbda,a,b,N)\n",
    "\n",
    "        H = obj_factor*H\n",
    "\n",
    "        row, col = self.hessianstructure()\n",
    "\n",
    "        return H[row, col]\n",
    "\n",
    "\n",
    "    def intermediate(self, alg_mod, iter_count, obj_value, inf_pr, inf_du, mu,\n",
    "                     d_norm, regularization_size, alpha_du, alpha_pr,\n",
    "                     ls_trials):\n",
    "        \"\"\"Prints information at every Ipopt iteration.\"\"\"\n",
    "        iterate = self.get_current_iterate()\n",
    "        infeas = self.get_current_violations()\n",
    "        primal = iterate[\"x\"]\n",
    "        jac = self.jacobian(primal)\n",
    "        msg = \"Objective value at iteration #{:d} is - {:g}\"\n",
    "\n",
    "        print(msg.format(iter_count, obj_value))\n",
    "        print(\"Primal iterate:\", primal)\n",
    "        #infeasi = []\n",
    "        #for i in range(len(X)):\n",
    "        #    infeasi.append(1/alpha * (primal[1]-X[i])-primal[3+i])\n",
    "       # print('infeasi:', np.max(infeasi))\n",
    "        print('inf_pr:', inf_pr)\n",
    "        #print(\"Flattened Jacobian:\", jac)\n",
    "        #print(\"Dual infeasibility:\", infeas[\"grad_lag_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59894b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### robust EU\n",
    "\n",
    "class HS075(cyipopt.Problem):\n",
    "    \n",
    "    \n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        lbda = x[1]\n",
    "        N = len(X)\n",
    "        som = 0\n",
    "        for i in range(2,N):\n",
    "            som = som + lbda * kl_c((the1-X[i])/lbda)\n",
    "        som = som/N - the1 + lbda*r\n",
    "        return(som)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        the1 = x[0]\n",
    "        lbda = x[1]\n",
    "        N = len(X)\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        grad = np.zeros(2)  \n",
    "        for i in range(N):\n",
    "            s1 = s1 + d_kl_c((the1-X[i])/lbda)/N\n",
    "            s2 = s2 + kl_c((the1-X[i])/lbda)/N - d_kl_c((the1-X[i])/lbda)/N * ((the1-X[i])/lbda)\n",
    "        grad[0] = -1 + s1\n",
    "        grad[1] = r + s2\n",
    "        return(grad)\n",
    "             \n",
    "        \n",
    "       \n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        cons = x[1]\n",
    "        return(cons)\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        return(np.array([0,1])) \n",
    "        \n",
    "    \n",
    "    \n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        struc = np.tril(np.ones((2,2)))\n",
    "        return np.nonzero(struc)\n",
    "\n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        N = len(X)\n",
    "        H = np.zeros((2,2))\n",
    "        t1 = x[0]\n",
    "        lbda = x[1]\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        s3 = 0\n",
    "        for i in range(N):\n",
    "            s1 = s1 + dd_kl_c((t1-X[i])/lbda)/lbda\n",
    "            s2 = s2 + (t1-X[i])**2/(lbda**3)*dd_kl_c((t1-X[i])/lbda)\n",
    "            fac1 = -(t1-X[i])/(lbda**2)\n",
    "            fac2 = 1/N*dd_kl_c((t1-X[i])/lbda)\n",
    "            s3 = s3 + fac1*fac2\n",
    "        H[0,0] = s1 * obj_factor + lagrange[0]\n",
    "        H[1,1] = s2 * obj_factor + lagrange[0]\n",
    "        H[1,0] = s3 * obj_factor\n",
    "\n",
    "        row, col = self.hessianstructure()\n",
    "\n",
    "        return H[row, col]\n",
    "\n",
    "\n",
    "    def intermediate(self, alg_mod, iter_count, obj_value, inf_pr, inf_du, mu,\n",
    "                     d_norm, regularization_size, alpha_du, alpha_pr,\n",
    "                     ls_trials):\n",
    "        \"\"\"Prints information at every Ipopt iteration.\"\"\"\n",
    "        iterate = self.get_current_iterate()\n",
    "        infeas = self.get_current_violations()\n",
    "        primal = iterate[\"x\"]\n",
    "        jac = self.jacobian(primal)\n",
    "        msg = \"Objective value at iteration #{:d} is - {:g}\"\n",
    "\n",
    "        print(msg.format(iter_count, obj_value))\n",
    "        print(\"Primal iterate:\", primal)\n",
    "        print('inf_pr:', inf_pr)\n",
    "        #print(\"Flattened Jacobian:\", jac)\n",
    "        #print(\"Dual infeasibility:\", infeas[\"grad_lag_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb31bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HS076(cyipopt.Problem):\n",
    "    \n",
    "    \n",
    "    def objective(self, x):\n",
    "        \"\"\"Returns the scalar value of the objective given x.\"\"\"\n",
    "        return(x[2]*kl_c((x[0]+x[3])/x[2])-x[0]-x[1]+x[2]*r)\n",
    "\n",
    "    def gradient(self, x):\n",
    "        \"\"\"Returns the gradient of the objective with respect to x.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        grad = np.zeros(4)\n",
    "        grad[0] = np.exp((x[0]+x[3])/x[2])-1\n",
    "        grad[1] = -1\n",
    "        grad[2] = kl_c((x[0]+x[3])/x[2]) - np.exp((x[0]+x[3])/x[2])* ((x[0]+x[3])/x[2])+ x[2]*r\n",
    "        grad[3] = np.exp((x[0]+x[3])/x[2])\n",
    "        \n",
    "        return(grad)\n",
    "             \n",
    "        \n",
    "       \n",
    "    def constraints(self, x):\n",
    "        \"\"\"Returns the constraints.\"\"\"\n",
    "        return([1/alpha*(x[1]+5.98)-x[3]])\n",
    "\n",
    "    def jacobian(self, x):\n",
    "        \"\"\"Returns the Jacobian of the constraints with respect to x.\"\"\"\n",
    "        return([0,1/alpha,0,-1]) \n",
    "        \n",
    "    def hessianstructure(self):\n",
    "        \"\"\"Returns the row and column indices for non-zero vales of the\n",
    "        Hessian.\"\"\"\n",
    "\n",
    "        # NOTE: The default hessian structure is of a lower triangular matrix,\n",
    "        # therefore this function is redundant. It is included as an example\n",
    "        # for structure callback.\n",
    "        #a,b,alpha,r = self.para\n",
    "        struc = np.tril(np.ones((4,4)))\n",
    "        return np.nonzero(struc)\n",
    "    \n",
    "    def hessian(self, x, lagrange, obj_factor):\n",
    "        \"\"\"Returns the non-zero values of the Hessian.\"\"\"\n",
    "        #a,b,alpha,r = self.para\n",
    "        H = np.zeros((4,4))\n",
    "        H[0,0] = 1/x[2]*np.exp((x[0]+x[3])/x[2])* obj_factor\n",
    "        H[2,0] = -(x[3]+x[0])/(x[2]**2)*np.exp((x[0]+x[3])/x[2])* obj_factor\n",
    "        H[3,0] = 1/x[2]*np.exp((x[0]+x[3])/x[2])* obj_factor\n",
    "        H[2,2] = np.exp((x[0]+x[3])/x[2])*((x[0]+x[3])**2/(x[2]**3))* obj_factor\n",
    "        H[3,2] = -(x[3]+x[0])/(x[2]**2)*np.exp((x[0]+x[3])/x[2])* obj_factor\n",
    "        H[3,3] = 1/x[2]*np.exp((x[0]+x[3])/x[2])* obj_factor\n",
    "        \n",
    "        row, col = self.hessianstructure()\n",
    "        return H[row, col]\n",
    "\n",
    "    def intermediate(self, alg_mod, iter_count, obj_value, inf_pr, inf_du, mu,\n",
    "                     d_norm, regularization_size, alpha_du, alpha_pr,\n",
    "                     ls_trials):\n",
    "        \"\"\"Prints information at every Ipopt iteration.\"\"\"\n",
    "        iterate = self.get_current_iterate()\n",
    "        infeas = self.get_current_violations()\n",
    "        primal = iterate[\"x\"]\n",
    "        jac = self.jacobian(primal)\n",
    "        msg = \"Objective value at iteration #{:d} is - {:g}\"\n",
    "\n",
    "        print(msg.format(iter_count, obj_value))\n",
    "        print(\"Primal iterate:\", primal)\n",
    "        print('inf_pr:', inf_pr)\n",
    "        #print(\"Flattened Jacobian:\", jac)\n",
    "        #print(\"Dual infeasibility:\", infeas[\"grad_lag_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fcc41d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011100838259683056"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00d97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lb = [-3,-2,9]\n",
    "ub = [-1, -1, 10]\n",
    "\n",
    "\n",
    "cl = []\n",
    "cu = []\n",
    "x0 = [-1,1,9.2]\n",
    "N = len(X)\n",
    "for i in range(3, N+3):\n",
    "    lb.append(0)\n",
    "    ub.append(1000)\n",
    "    cl.append(-1000)\n",
    "    cu.append(0.1)\n",
    "    x0.append(np.maximum(1/alpha*(x0[1]-X[i-3]),0)+0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd448d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, -5.981243403948075, 1, 0.1, 0.1, 0.1, 0.1, 0.1]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a2cfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [-1000,0.01]\n",
    "ub = [1000, 100]\n",
    "\n",
    "\n",
    "cl = [0]\n",
    "cu = [100000]\n",
    "x0 = [0.5,1.1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d3375b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [-500,-500,0.01,0.01]\n",
    "ub = [500,500,500,500]\n",
    "cl = [-500]\n",
    "cu = [0.1]\n",
    "x0 = [1,X[0],1,1/alpha*(X[0]-X[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3329a4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a71ef059",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HS071.__init__() got an unexpected keyword argument 'n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m HS071(\n\u001b[0;32m      2\u001b[0m     n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x0),\n\u001b[0;32m      3\u001b[0m     m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(cl),\n\u001b[0;32m      4\u001b[0m     lb\u001b[38;5;241m=\u001b[39mlb,\n\u001b[0;32m      5\u001b[0m     ub\u001b[38;5;241m=\u001b[39mub,\n\u001b[0;32m      6\u001b[0m     cl\u001b[38;5;241m=\u001b[39mcl,\n\u001b[0;32m      7\u001b[0m     cu\u001b[38;5;241m=\u001b[39mcu,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m     10\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m6000\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: HS071.__init__() got an unexpected keyword argument 'n'"
     ]
    }
   ],
   "source": [
    "nlp = HS071(\n",
    "    n=len(x0),\n",
    "    m=len(cl),\n",
    "    lb=lb,\n",
    "    ub=ub,\n",
    "    cl=cl,\n",
    "    cu=cu,\n",
    ")\n",
    "nlp.add_option('tol', 1e-8)\n",
    "nlp.add_option('max_iter', 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "55c04732",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HS074.hessian() missing 2 required positional arguments: 'lagrange' and 'obj_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp\u001b[38;5;241m.\u001b[39mhessian(x0)\n",
      "\u001b[1;31mTypeError\u001b[0m: HS074.hessian() missing 2 required positional arguments: 'lagrange' and 'obj_factor'"
     ]
    }
   ],
   "source": [
    "nlp.hessian(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9b4a6ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at iteration #0 is - -6.45437\n",
      "Primal iterate: [-2.98000003 -1.99000002  9.00999991  0.1         0.1         0.1\n",
      "  0.1         0.1       ]\n",
      "inf_pr: 7.792486758496151\n",
      "Objective value at iteration #1 is - -6.41187\n",
      "Primal iterate: [-2.97926299 -1.99123752  9.01070894  0.11083756  0.11083756  0.11083756\n",
      "  0.11083756  0.11083756]\n",
      "inf_pr: 7.778881792400333\n",
      "Objective value at iteration #2 is - 16.3566\n",
      "Primal iterate: [-2.87657498 -1.95024176  9.11134996  4.78558965  4.78558965  4.78558965\n",
      "  4.78558965  4.78558965]\n",
      "inf_pr: 3.240967345337817\n",
      "Objective value at iteration #3 is - 21.0331\n",
      "Primal iterate: [-2.81252656 -1.88619383  9.19973504  5.47134373  5.47134373  5.47134373\n",
      "  5.47134373  5.47134373]\n",
      "inf_pr: 2.7430163113081543\n",
      "Objective value at iteration #4 is - 24.8364\n",
      "Primal iterate: [-2.83049181 -1.00886193  9.26778273  6.16552949  6.16552949  6.16552949\n",
      "  6.16552949  6.16552949]\n",
      "inf_pr: 3.850481021365007\n",
      "Objective value at iteration #5 is - 35.0353\n",
      "Primal iterate: [-2.85245989 -1.12286987  9.59172616  7.52489766  7.52489766  7.52489766\n",
      "  7.52489766  7.52489766]\n",
      "inf_pr: 2.411818242436943\n",
      "Objective value at iteration #6 is - 38.6974\n",
      "Primal iterate: [-2.86867261 -1.20139026  9.62010453  7.97277883  7.97277883  7.97277883\n",
      "  7.97277883  7.97277883]\n",
      "inf_pr: 1.7915246547285897\n",
      "Objective value at iteration #7 is - 41.6302\n",
      "Primal iterate: [-2.87718131 -1.22143572  9.65217085  8.32096666  8.32096666  8.32096666\n",
      "  8.32096666  8.32096666]\n",
      "inf_pr: 1.3927513433561476\n",
      "Objective value at iteration #8 is - 43.9925\n",
      "Primal iterate: [-2.88364226 -1.23128047  9.67631143  8.59396686  8.59396686  8.59396686\n",
      "  8.59396686  8.59396686]\n",
      "inf_pr: 1.0920008076544518\n",
      "Objective value at iteration #9 is - 45.8894\n",
      "Primal iterate: [-2.88836532 -1.23928594  9.69452808  8.80793601  8.80793601  8.80793601\n",
      "  8.80793601  8.80793601]\n",
      "inf_pr: 0.8558765753290798\n",
      "Objective value at iteration #10 is - 46.4897\n",
      "Primal iterate: [-2.97241339 -1.13021742  9.81045803  8.97643773  8.97643773  8.97643773\n",
      "  8.97643773  8.97643773]\n",
      "inf_pr: 0.6740068877854017\n",
      "Objective value at iteration #11 is - 47.7234\n",
      "Primal iterate: [-2.97712318 -1.06884699  9.9235515   9.13693129  9.13693129  9.13693129\n",
      "  9.13693129  9.13693129]\n",
      "inf_pr: 0.6419742622533322\n",
      "Objective value at iteration #12 is - 50.6181\n",
      "Primal iterate: [-2.97853435 -1.07658715  9.92015785  9.44327242  9.44327242  9.44327242\n",
      "  9.44327242  9.44327242]\n",
      "inf_pr: 0.31841309520334465\n",
      "Objective value at iteration #13 is - 51.2172\n",
      "Primal iterate: [-2.97873845 -1.0787886   9.92346285  9.5060155   9.5060155   9.5060155\n",
      "  9.5060155   9.5060155 ]\n",
      "inf_pr: 0.2509723105203154\n",
      "Objective value at iteration #14 is - 51.6943\n",
      "Primal iterate: [-2.97894893 -1.08000178  9.92516757  9.55567361  9.55567361  9.55567361\n",
      "  9.55567361  9.55567361]\n",
      "inf_pr: 0.19863245688720282\n",
      "Objective value at iteration #15 is - 52.3398\n",
      "Primal iterate: [-2.99700655 -1.01992813  9.98531764  9.65462834  9.65462834  9.65462834\n",
      "  9.65462834  9.65462834]\n",
      "inf_pr: 0.17487565114252637\n",
      "Objective value at iteration #16 is - 52.6958\n",
      "Primal iterate: [-2.99704225 -1.01281462  9.98913607  9.69252244  9.69252244  9.69252244\n",
      "  9.69252244  9.69252244]\n",
      "inf_pr: 0.1515763886284004\n",
      "Objective value at iteration #17 is - 52.9919\n",
      "Primal iterate: [-2.99706031 -1.01290439  9.98921751  9.72279716  9.72279716  9.72279716\n",
      "  9.72279716  9.72279716]\n",
      "inf_pr: 0.1210988737546226\n",
      "Objective value at iteration #18 is - 53.2289\n",
      "Primal iterate: [-2.99707466 -1.01301691  9.98934764  9.74696845  9.74696845  9.74696845\n",
      "  9.74696845  9.74696845]\n",
      "inf_pr: 0.09668516825625012\n",
      "Objective value at iteration #19 is - 53.4186\n",
      "Primal iterate: [-2.99708604 -1.01310869  9.98944896  9.766266    9.766266    9.766266\n",
      "  9.766266    9.766266  ]\n",
      "inf_pr: 0.077190203921109\n",
      "Objective value at iteration #20 is - 53.5702\n",
      "Primal iterate: [-2.99709509 -1.01318297  9.9895289   9.78167212  9.78167212  9.78167212\n",
      "  9.78167212  9.78167212]\n",
      "inf_pr: 0.061624483848084416\n",
      "Objective value at iteration #21 is - 53.6915\n",
      "Primal iterate: [-2.99710228 -1.01324292  9.98959211  9.79397128  9.79397128  9.79397128\n",
      "  9.79397128  9.79397128]\n",
      "inf_pr: 0.04919662599236743\n",
      "Objective value at iteration #22 is - 53.7884\n",
      "Primal iterate: [-2.99710801 -1.0132912   9.98964219  9.80378989  9.80378989  9.80378989\n",
      "  9.80378989  9.80378989]\n",
      "inf_pr: 0.03927443930139046\n",
      "Objective value at iteration #23 is - 53.8658\n",
      "Primal iterate: [-2.99711257 -1.01333001  9.98968192  9.81162813  9.81162813  9.81162813\n",
      "  9.81162813  9.81162813]\n",
      "inf_pr: 0.0313529735998067\n",
      "Objective value at iteration #24 is - 53.9276\n",
      "Primal iterate: [-2.9971162  -1.01336117  9.98971349  9.81788537  9.81788537  9.81788537\n",
      "  9.81788537  9.81788537]\n",
      "inf_pr: 0.025028954195169664\n",
      "Objective value at iteration #25 is - 54.0819\n",
      "Primal iterate: [-2.99984951 -1.0009767   9.9994098   9.83890308  9.83890308  9.83890308\n",
      "  9.83890308  9.83890308]\n",
      "inf_pr: 0.021997381447062717\n",
      "Objective value at iteration #26 is - 54.1263\n",
      "Primal iterate: [-2.99984695 -1.00072652  9.99945208  9.84340509  9.84340509  9.84340509\n",
      "  9.84340509  9.84340509]\n",
      "inf_pr: 0.018008047443261038\n",
      "Objective value at iteration #27 is - 54.162\n",
      "Primal iterate: [-2.99984706 -1.00072714  9.99945296  9.84700642  9.84700642  9.84700642\n",
      "  9.84700642  9.84700642]\n",
      "inf_pr: 0.014405338084445857\n",
      "Objective value at iteration #28 is - 54.1905\n",
      "Primal iterate: [-2.99984715 -1.00072794  9.99945374  9.84988715  9.84988715  9.84988715\n",
      "  9.84988715  9.84988715]\n",
      "inf_pr: 0.011522896323153106\n",
      "Objective value at iteration #29 is - 54.2134\n",
      "Primal iterate: [-2.99984722 -1.00072859  9.99945436  9.85219145  9.85219145  9.85219145\n",
      "  9.85219145  9.85219145]\n",
      "inf_pr: 0.009217215029704254\n",
      "Objective value at iteration #30 is - 54.2317\n",
      "Primal iterate: [-2.99984728 -1.00072911  9.99945485  9.85403467  9.85403467  9.85403467\n",
      "  9.85403467  9.85403467]\n",
      "inf_pr: 0.00737288911909513\n",
      "Objective value at iteration #31 is - 54.2463\n",
      "Primal iterate: [-2.99984732 -1.00072952  9.99945525  9.85550907  9.85550907  9.85550907\n",
      "  9.85550907  9.85550907]\n",
      "inf_pr: 0.005897604167248896\n",
      "Objective value at iteration #32 is - 54.258\n",
      "Primal iterate: [-2.99984736 -1.00072985  9.99945557  9.85668845  9.85668845  9.85668845\n",
      "  9.85668845  9.85668845]\n",
      "inf_pr: 0.004717517129499263\n",
      "Objective value at iteration #33 is - 54.2674\n",
      "Primal iterate: [-2.99984739 -1.00073012  9.99945582  9.85763184  9.85763184  9.85763184\n",
      "  9.85763184  9.85763184]\n",
      "inf_pr: 0.003773560429505385\n",
      "Objective value at iteration #34 is - 54.2749\n",
      "Primal iterate: [-2.99984741 -1.00073033  9.99945602  9.85838647  9.85838647  9.85838647\n",
      "  9.85838647  9.85838647]\n",
      "inf_pr: 0.003018485534078283\n",
      "Objective value at iteration #35 is - 54.2809\n",
      "Primal iterate: [-2.99984743 -1.0007305   9.99945618  9.85899009  9.85899009  9.85899009\n",
      "  9.85899009  9.85899009]\n",
      "inf_pr: 0.0024144980647951425\n",
      "Objective value at iteration #36 is - 54.2857\n",
      "Primal iterate: [-2.99984744 -1.00073064  9.99945631  9.85947293  9.85947293  9.85947293\n",
      "  9.85947293  9.85947293]\n",
      "inf_pr: 0.001931366093923137\n",
      "Objective value at iteration #37 is - 54.2895\n",
      "Primal iterate: [-2.99984746 -1.00073074  9.99945642  9.85985916  9.85985916  9.85985916\n",
      "  9.85985916  9.85985916]\n",
      "inf_pr: 0.0015449069497942558\n",
      "Objective value at iteration #38 is - 54.2926\n",
      "Primal iterate: [-2.99984747 -1.00073083  9.9994565   9.8601681   9.8601681   9.8601681\n",
      "  9.8601681   9.8601681 ]\n",
      "inf_pr: 0.0012357767981715923\n",
      "Objective value at iteration #39 is - 54.3007\n",
      "Primal iterate: [-2.99999817 -1.00000976  9.9999933   9.86129243  9.86129243  9.86129243\n",
      "  9.86129243  9.86129243]\n",
      "inf_pr: 0.0011794589954579465\n",
      "Objective value at iteration #40 is - 54.303\n",
      "Primal iterate: [-2.99999816 -1.00000896  9.99999343  9.86152865  9.86152865  9.86152865\n",
      "  9.86152865  9.86152865]\n",
      "inf_pr: 0.0009448672289858601\n",
      "Objective value at iteration #41 is - 54.3049\n",
      "Primal iterate: [-2.99999816 -1.00000896  9.99999343  9.86171762  9.86171762  9.86171762\n",
      "  9.86171762  9.86171762]\n",
      "inf_pr: 0.0007558927789630548\n",
      "Objective value at iteration #42 is - 54.3064\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.8618688   9.8618688   9.8618688\n",
      "  9.8618688   9.8618688 ]\n",
      "inf_pr: 0.0006047133279296901\n",
      "Objective value at iteration #43 is - 54.3076\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86198974  9.86198974  9.86198974\n",
      "  9.86198974  9.86198974]\n",
      "inf_pr: 0.00048376994606996737\n",
      "Objective value at iteration #44 is - 54.3086\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86208649  9.86208649  9.86208649\n",
      "  9.86208649  9.86208649]\n",
      "inf_pr: 0.0003870153837897683\n",
      "Objective value at iteration #45 is - 54.3094\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.8621639   9.8621639   9.8621639\n",
      "  9.8621639   9.8621639 ]\n",
      "inf_pr: 0.00030961184854913504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at iteration #46 is - 54.31\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86222582  9.86222582  9.86222582\n",
      "  9.86222582  9.86222582]\n",
      "inf_pr: 0.00024768911203428\n",
      "Objective value at iteration #47 is - 54.3105\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86227536  9.86227536  9.86227536\n",
      "  9.86227536  9.86227536]\n",
      "inf_pr: 0.00019815099617294385\n",
      "Objective value at iteration #48 is - 54.3109\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86231499  9.86231499  9.86231499\n",
      "  9.86231499  9.86231499]\n",
      "inf_pr: 0.00015852056216592025\n",
      "Objective value at iteration #49 is - 54.3112\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86234669  9.86234669  9.86234669\n",
      "  9.86234669  9.86234669]\n",
      "inf_pr: 0.0001268162619105645\n",
      "Objective value at iteration #50 is - 54.3114\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86237205  9.86237205  9.86237205\n",
      "  9.86237205  9.86237205]\n",
      "inf_pr: 0.00010145285926631276\n",
      "Objective value at iteration #51 is - 54.3116\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86239235  9.86239235  9.86239235\n",
      "  9.86239235  9.86239235]\n",
      "inf_pr: 8.11621672012347e-05\n",
      "Objective value at iteration #52 is - 54.3118\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86240858  9.86240858  9.86240858\n",
      "  9.86240858  9.86240858]\n",
      "inf_pr: 6.49296375928865e-05\n",
      "Objective value at iteration #53 is - 54.3119\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999343  9.86242156  9.86242156  9.86242156\n",
      "  9.86242156  9.86242156]\n",
      "inf_pr: 5.1943633137777057e-05\n",
      "Objective value at iteration #54 is - 54.312\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999344  9.86243195  9.86243195  9.86243195\n",
      "  9.86243195  9.86243195]\n",
      "inf_pr: 4.1554844959434956e-05\n",
      "Objective value at iteration #55 is - 54.3121\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999344  9.86244026  9.86244026  9.86244026\n",
      "  9.86244026  9.86244026]\n",
      "inf_pr: 3.3243826726925274e-05\n",
      "Objective value at iteration #56 is - 54.3122\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999344  9.86244691  9.86244691  9.86244691\n",
      "  9.86244691  9.86244691]\n",
      "inf_pr: 2.659502198940067e-05\n",
      "Objective value at iteration #57 is - 54.3122\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999344  9.86245223  9.86245223  9.86245223\n",
      "  9.86245223  9.86245223]\n",
      "inf_pr: 2.127598607611081e-05\n",
      "Objective value at iteration #58 is - 54.3123\n",
      "Primal iterate: [-2.99999816 -1.00000897  9.99999344  9.86245649  9.86245649  9.86245649\n",
      "  9.86245649  9.86245649]\n",
      "inf_pr: 1.7020763650135717e-05\n",
      "Objective value at iteration #59 is - 54.3124\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86247128  9.86247128  9.86247128\n",
      "  9.86247128  9.86247128]\n",
      "inf_pr: 1.5520359854970245e-05\n",
      "Objective value at iteration #60 is - 54.3124\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86247438  9.86247438  9.86247438\n",
      "  9.86247438  9.86247438]\n",
      "inf_pr: 1.2416493441969045e-05\n",
      "Objective value at iteration #61 is - 54.3124\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86247687  9.86247687  9.86247687\n",
      "  9.86247687  9.86247687]\n",
      "inf_pr: 9.933194734176864e-06\n",
      "Objective value at iteration #62 is - 54.3124\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86247885  9.86247885  9.86247885\n",
      "  9.86247885  9.86247885]\n",
      "inf_pr: 7.946555771132235e-06\n",
      "Objective value at iteration #63 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248044  9.86248044  9.86248044\n",
      "  9.86248044  9.86248044]\n",
      "inf_pr: 6.3572446056814336e-06\n",
      "Objective value at iteration #64 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248171  9.86248171  9.86248171\n",
      "  9.86248171  9.86248171]\n",
      "inf_pr: 5.0857956747363264e-06\n",
      "Objective value at iteration #65 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248273  9.86248273  9.86248273\n",
      "  9.86248273  9.86248273]\n",
      "inf_pr: 4.068636533183234e-06\n",
      "Objective value at iteration #66 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248354  9.86248354  9.86248354\n",
      "  9.86248354  9.86248354]\n",
      "inf_pr: 3.2549092213590702e-06\n",
      "Objective value at iteration #67 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.8624842   9.8624842   9.8624842\n",
      "  9.8624842   9.8624842 ]\n",
      "inf_pr: 2.6039273711836453e-06\n",
      "Objective value at iteration #68 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248472  9.86248472  9.86248472\n",
      "  9.86248472  9.86248472]\n",
      "inf_pr: 2.083141892122997e-06\n",
      "Objective value at iteration #69 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248513  9.86248513  9.86248513\n",
      "  9.86248513  9.86248513]\n",
      "inf_pr: 1.6665135102872375e-06\n",
      "Objective value at iteration #70 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248547  9.86248547  9.86248547\n",
      "  9.86248547  9.86248547]\n",
      "inf_pr: 1.333210805531948e-06\n",
      "Objective value at iteration #71 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248573  9.86248573  9.86248573\n",
      "  9.86248573  9.86248573]\n",
      "inf_pr: 1.0665686427935306e-06\n",
      "Objective value at iteration #72 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248595  9.86248595  9.86248595\n",
      "  9.86248595  9.86248595]\n",
      "inf_pr: 8.532549133077882e-07\n",
      "Objective value at iteration #73 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248612  9.86248612  9.86248612\n",
      "  9.86248612  9.86248612]\n",
      "inf_pr: 6.826039282981089e-07\n",
      "Objective value at iteration #74 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248625  9.86248625  9.86248625\n",
      "  9.86248625  9.86248625]\n",
      "inf_pr: 5.460831406511879e-07\n",
      "Objective value at iteration #75 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248636  9.86248636  9.86248636\n",
      "  9.86248636  9.86248636]\n",
      "inf_pr: 4.368665101756042e-07\n",
      "Objective value at iteration #76 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248645  9.86248645  9.86248645\n",
      "  9.86248645  9.86248645]\n",
      "inf_pr: 3.4949320863730815e-07\n",
      "Objective value at iteration #77 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248652  9.86248652  9.86248652\n",
      "  9.86248652  9.86248652]\n",
      "inf_pr: 2.795945670541755e-07\n",
      "Objective value at iteration #78 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248658  9.86248658  9.86248658\n",
      "  9.86248658  9.86248658]\n",
      "inf_pr: 2.236756530688e-07\n",
      "Objective value at iteration #79 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248662  9.86248662  9.86248662\n",
      "  9.86248662  9.86248662]\n",
      "inf_pr: 1.7894052010969386e-07\n",
      "Objective value at iteration #80 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248666  9.86248666  9.86248666\n",
      "  9.86248666  9.86248666]\n",
      "inf_pr: 1.4315241694817793e-07\n",
      "Objective value at iteration #81 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248669  9.86248669  9.86248669\n",
      "  9.86248669  9.86248669]\n",
      "inf_pr: 1.1452193404704047e-07\n",
      "Objective value at iteration #82 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248671  9.86248671  9.86248671\n",
      "  9.86248671  9.86248671]\n",
      "inf_pr: 9.161754808972855e-08\n",
      "Objective value at iteration #83 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248673  9.86248673  9.86248673\n",
      "  9.86248673  9.86248673]\n",
      "inf_pr: 7.329403825528935e-08\n",
      "Objective value at iteration #84 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248674  9.86248674  9.86248674\n",
      "  9.86248674  9.86248674]\n",
      "inf_pr: 5.863522897775475e-08\n",
      "Objective value at iteration #85 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248675  9.86248675  9.86248675\n",
      "  9.86248675  9.86248675]\n",
      "inf_pr: 4.690818296293475e-08\n",
      "Objective value at iteration #86 is - 54.3125\n",
      "Primal iterate: [-3.00000003 -1.         10.00000009  9.86248676  9.86248676  9.86248676\n",
      "  9.86248676  9.86248676]\n",
      "inf_pr: 3.7526546162180985e-08\n"
     ]
    }
   ],
   "source": [
    "x, info = nlp.solve(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1708d88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([-3.00000003, -1.        , 10.00000009,  9.86248676,  9.86248676,\n",
       "         9.86248676,  9.86248676,  9.86248676]),\n",
       " 'g': array([  0.10000004,  -8.7678918 ,  -9.65987318, -11.55222705,\n",
       "        -10.34696622]),\n",
       " 'obj_val': 54.31252316752683,\n",
       " 'mult_g': array([3.97250090e-01, 2.80053588e-10, 2.54225404e-10, 2.12522716e-10,\n",
       "        2.37336918e-10]),\n",
       " 'mult_x_L': array([9.86250455e-01, 2.50590352e-09, 2.50590311e-09, 2.54084352e-10,\n",
       "        2.54084352e-10, 2.54084352e-10, 2.54084352e-10, 2.54084352e-10]),\n",
       " 'mult_x_U': array([1.25295176e-09, 2.05499822e-01, 2.76811275e-01, 2.53086415e-12,\n",
       "        2.53086415e-12, 2.53086415e-12, 2.53086415e-12, 2.53086415e-12]),\n",
       " 'status': 1,\n",
       " 'status_msg': b'Algorithm stopped at a point that was converged, not to \"desired\" tolerances, but to \"acceptable\" tolerances (see the acceptable-... options).'}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b083fab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e09486c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HS071' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m cyipopt\u001b[38;5;241m.\u001b[39mProblem(\n\u001b[0;32m      2\u001b[0m    n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x0),\n\u001b[0;32m      3\u001b[0m    m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(cl),\n\u001b[1;32m----> 4\u001b[0m    problem_obj\u001b[38;5;241m=\u001b[39mHS071(X,para),\n\u001b[0;32m      5\u001b[0m    lb\u001b[38;5;241m=\u001b[39mlb,\n\u001b[0;32m      6\u001b[0m    ub\u001b[38;5;241m=\u001b[39mub,\n\u001b[0;32m      7\u001b[0m    cl\u001b[38;5;241m=\u001b[39mcl,\n\u001b[0;32m      8\u001b[0m    cu\u001b[38;5;241m=\u001b[39mcu,\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HS071' is not defined"
     ]
    }
   ],
   "source": [
    "nlp = cyipopt.Problem(\n",
    "   n=len(x0),\n",
    "   m=len(cl),\n",
    "   problem_obj=HS071(X,para),\n",
    "   lb=lb,\n",
    "   ub=ub,\n",
    "   cl=cl,\n",
    "   cu=cu,\n",
    ")\n",
    "\n",
    "nlp.add_option('mu_strategy', 'adaptive')\n",
    "nlp.add_option('tol', 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de44351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996979999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.707**2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50873a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259.249736157923"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/alpha*(0.5-X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ed2fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent_backtracking(func, grad_f, x0, alfa=0.1, beta=0.7, max_iter=100, tol=1e-6):\n",
    "    x = x0\n",
    "    for i in range(max_iter):\n",
    "        gradient = grad_f(x)\n",
    "        step_size = 1.0\n",
    "        while func(x - step_size * gradient) > func(x) - alfa * step_size * np.linalg.norm(gradient,2)**2:\n",
    "            step_size *= beta\n",
    "        x = x - step_size * gradient\n",
    "        print('obj:',func(x), 'grad_norm:',np.linalg.norm(gradient,2), 't:', step_size)\n",
    "        if np.linalg.norm(gradient,2) < tol:\n",
    "            break\n",
    "    return x\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "def log_bar(x):\n",
    "    if x>0:\n",
    "        return(-np.log(x))\n",
    "    else:\n",
    "        return(np.inf)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the function f(x) and its gradient grad_f(x)\n",
    "    def func(x):\n",
    "        mu = 0.01\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(X)\n",
    "        som = 0\n",
    "        sb_1 = 0\n",
    "        for i in range(3,N+3):\n",
    "            som = som + lbda * kl_c((x[i]+the1)/lbda)\n",
    "            sb_1 = sb_1 +log_bar(x[i]-1/alpha * (x[1]-X[i-3])) + log_bar(x[i])\n",
    "        return(-the1-the2+lbda*r+som/N +mu*sb_1+mu*log_bar(x[2]))\n",
    "        \n",
    "\n",
    "    def grad_f(x):\n",
    "        # Replace this with the gradient of your actual function\n",
    "        mu = 0.01\n",
    "        the1 = x[0]\n",
    "        the2 = x[1]\n",
    "        lbda = x[2]\n",
    "        N = len(X)\n",
    "        s1 = 0\n",
    "        s2 = 0\n",
    "        sb1 = 0\n",
    "        grad = np.zeros(N+3) \n",
    "        for i in range(3,N+3):\n",
    "            grad[i] = d_kl_c((x[i]+the1)/lbda)/N-mu/(x[i]-1/alpha*(x[1]-X[i-3]))-mu/x[i]\n",
    "            s1 = s1 + d_kl_c((x[i]+the1)/lbda)/N\n",
    "            s2 = s2 + kl_c((x[i]+the1)/lbda) - d_kl_c((x[i]+the1)/lbda)*((x[i]+the1)/lbda)\n",
    "            sb1 = sb1 + mu/(alpha*x[i]-x[1]+X[i-3])\n",
    "        grad[1] = -1 + sb1\n",
    "        grad[0] = -1 + s1\n",
    "        grad[2] = r + s2/N - mu/lbda\n",
    "        \n",
    "        return(grad)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ac0e9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [-4,np.min(X),1]\n",
    "N = len(X)\n",
    "for i in range(3, N+3):\n",
    "    x0.append(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "019a65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj: 9.021700896104292 grad_norm: 1.5234234328794394 t: 0.05764800999999997\n",
      "obj: 7.666817372272944 grad_norm: 1.396292027264688 t: 1.0\n",
      "obj: 7.290348112830379 grad_norm: 1.272204290461535 t: 0.24009999999999992\n",
      "obj: 7.1937142609886395 grad_norm: 1.162333841846327 t: 0.08235429999999996\n",
      "obj: 7.141789798750256 grad_norm: 0.9979853286391682 t: 0.11764899999999995\n",
      "obj: 7.055535510199991 grad_norm: 1.12820785590976 t: 0.08235429999999996\n",
      "obj: 7.048184039000628 grad_norm: 1.602140307597879 t: 0.006782230728489994\n",
      "obj: 7.0163796594811565 grad_norm: 0.8310423019452037 t: 0.05764800999999997\n",
      "obj: 7.00912727166919 grad_norm: 2.6893762751580255 t: 0.002326305139872068\n",
      "obj: 6.6287239064559795 grad_norm: 0.8249295927138163 t: 1.0\n",
      "obj: 6.38293881366661 grad_norm: 1.0751534380353733 t: 0.24009999999999992\n",
      "obj: 6.378581697016648 grad_norm: 1.6310840000200537 t: 0.003323293056960097\n",
      "obj: 6.223655748685367 grad_norm: 0.5737746882403322 t: 1.0\n",
      "obj: 6.110849898770839 grad_norm: 1.0018130299797834 t: 0.11764899999999995\n",
      "obj: 6.093000798514583 grad_norm: 0.8593903357332775 t: 0.05764800999999997\n",
      "obj: 6.084382245369754 grad_norm: 5.870904906882704 t: 0.0005585458640832833\n",
      "obj: 6.081356006570985 grad_norm: 1.1949525378934542 t: 0.004747561509942996\n",
      "obj: 5.95411521487095 grad_norm: 0.3905585875569091 t: 1.0\n",
      "obj: 5.950998928690904 grad_norm: 0.5010072529940388 t: 0.019773267429999988\n",
      "obj: 5.948588673051996 grad_norm: 0.30152762148920154 t: 0.05764800999999997\n",
      "obj: 5.945630276181293 grad_norm: 0.49270997809158185 t: 0.019773267429999988\n",
      "obj: 5.9437688212504485 grad_norm: 0.3011213809295613 t: 0.04035360699999998\n",
      "obj: 5.941729998007836 grad_norm: 0.421431481981486 t: 0.019773267429999988\n",
      "obj: 5.940566272045274 grad_norm: 0.3340759015910733 t: 0.019773267429999988\n",
      "obj: 5.939231040583253 grad_norm: 0.3270116257251897 t: 0.028247524899999984\n",
      "obj: 5.938068327461485 grad_norm: 0.5731434753279948 t: 0.006782230728489994\n",
      "obj: 5.920856975951898 grad_norm: 0.2500795068835164 t: 0.48999999999999994\n",
      "obj: 5.912153682063349 grad_norm: 6.009605135940935 t: 0.0005585458640832833\n",
      "obj: 5.910088364245166 grad_norm: 1.0892883116356034 t: 0.003323293056960097\n",
      "obj: 5.909314843031103 grad_norm: 0.2722528100303856 t: 0.019773267429999988\n",
      "obj: 5.90840968832031 grad_norm: 0.27233815578630866 t: 0.019773267429999988\n",
      "obj: 5.907664994499856 grad_norm: 0.2736423511332559 t: 0.019773267429999988\n",
      "obj: 5.906775270046951 grad_norm: 0.27373860652851845 t: 0.019773267429999988\n",
      "obj: 5.906058951458124 grad_norm: 0.275073359533421 t: 0.019773267429999988\n",
      "obj: 5.905183876696374 grad_norm: 0.2751707527986895 t: 0.019773267429999988\n",
      "obj: 5.904495435507582 grad_norm: 0.2765154715827104 t: 0.019773267429999988\n",
      "obj: 5.9036343130184115 grad_norm: 0.2766069088687986 t: 0.019773267429999988\n",
      "obj: 5.902973214545371 grad_norm: 0.27794557577315193 t: 0.019773267429999988\n",
      "obj: 5.902125420888314 grad_norm: 0.2780265512514124 t: 0.019773267429999988\n",
      "obj: 5.901491104230599 grad_norm: 0.2793478938704366 t: 0.019773267429999988\n",
      "obj: 5.900656077627068 grad_norm: 0.27941616252876245 t: 0.019773267429999988\n",
      "obj: 5.900066662573859 grad_norm: 0.28071330166587605 t: 0.01384128720099999\n",
      "obj: 5.899224627447586 grad_norm: 0.22263022195751145 t: 0.028247524899999984\n",
      "obj: 5.898620458697529 grad_norm: 0.3301916413332724 t: 0.01384128720099999\n",
      "obj: 5.897947802768273 grad_norm: 0.24376874735822707 t: 0.028247524899999984\n",
      "obj: 5.897210926573313 grad_norm: 0.4308292572272506 t: 0.009688901040699992\n",
      "obj: 5.896444841199616 grad_norm: 0.2133578005779993 t: 0.04035360699999998\n",
      "obj: 5.895545184487836 grad_norm: 0.5264523034626543 t: 0.006782230728489994\n",
      "obj: 5.89083189194329 grad_norm: 0.18395071946566743 t: 0.3429999999999999\n",
      "obj: 5.885064349903098 grad_norm: 2.9567575424521637 t: 0.0016284135979104473\n",
      "obj: 5.884499676883267 grad_norm: 0.36808477529333444 t: 0.009688901040699992\n",
      "obj: 5.883863234018944 grad_norm: 0.18264317168891422 t: 0.04035360699999998\n",
      "obj: 5.883247950825087 grad_norm: 0.41373707797197784 t: 0.006782230728489994\n",
      "obj: 5.862228161720858 grad_norm: 0.15877212310937966 t: 1.0\n",
      "obj: 5.8618064522700495 grad_norm: 0.11820505020416265 t: 0.05764800999999997\n",
      "obj: 5.86144540958246 grad_norm: 0.314494628119839 t: 0.006782230728489994\n",
      "obj: 5.85348425990685 grad_norm: 0.10886255524072656 t: 1.0\n",
      "obj: 5.850952390580867 grad_norm: 0.5081267220486229 t: 0.019773267429999988\n",
      "obj: 5.850739587396503 grad_norm: 0.22555817380136794 t: 0.009688901040699992\n",
      "obj: 5.850566162828501 grad_norm: 0.1017468971625331 t: 0.028247524899999984\n",
      "obj: 5.850430768462229 grad_norm: 0.15046812372492863 t: 0.01384128720099999\n",
      "obj: 5.850287457148213 grad_norm: 0.11590065269416848 t: 0.019773267429999988\n",
      "obj: 5.850162011381137 grad_norm: 0.12983843532015896 t: 0.01384128720099999\n",
      "obj: 5.850006637094402 grad_norm: 0.10526889770289174 t: 0.028247524899999984\n",
      "obj: 5.849861333692861 grad_norm: 0.16716635253864537 t: 0.009688901040699992\n",
      "obj: 5.84955805381209 grad_norm: 0.09192432194816848 t: 0.08235429999999996\n",
      "obj: 5.84918658213731 grad_norm: 0.33365420295694526 t: 0.006782230728489994\n",
      "obj: 5.84209863229312 grad_norm: 0.08621802377698572 t: 1.0\n",
      "obj: 5.841725030366801 grad_norm: 0.08354725466271523 t: 0.11764899999999995\n",
      "obj: 5.841289219897793 grad_norm: 0.25803836739565666 t: 0.01384128720099999\n",
      "obj: 5.841184081492699 grad_norm: 0.10913665269848938 t: 0.019773267429999988\n",
      "obj: 5.841065630373785 grad_norm: 0.12081243902438991 t: 0.01384128720099999\n",
      "obj: 5.840921126237511 grad_norm: 0.09181407956427992 t: 0.04035360699999998\n",
      "obj: 5.840736900119636 grad_norm: 0.16746840343406166 t: 0.01384128720099999\n",
      "obj: 5.8406284037600145 grad_norm: 0.10319396051646346 t: 0.019773267429999988\n",
      "obj: 5.840516704798772 grad_norm: 0.11326066935473046 t: 0.019773267429999988\n",
      "obj: 5.840409298930431 grad_norm: 0.13177967008367147 t: 0.01384128720099999\n",
      "obj: 5.840295278586774 grad_norm: 0.10323979277452561 t: 0.019773267429999988\n",
      "obj: 5.840194099356843 grad_norm: 0.11694129573874812 t: 0.01384128720099999\n",
      "obj: 5.84007231567925 grad_norm: 0.09546728869947484 t: 0.028247524899999984\n",
      "obj: 5.839950234631464 grad_norm: 0.1545568916528524 t: 0.009688901040699992\n",
      "obj: 5.8397156423230685 grad_norm: 0.08347315475322041 t: 0.05764800999999997\n",
      "obj: 5.83954299076175 grad_norm: 0.20299985500365736 t: 0.009688901040699992\n",
      "obj: 5.8394085038530985 grad_norm: 0.09097285000063482 t: 0.028247524899999984\n",
      "obj: 5.839300175985244 grad_norm: 0.1369545259588862 t: 0.01384128720099999\n",
      "obj: 5.839188776263814 grad_norm: 0.10590909519812887 t: 0.019773267429999988\n",
      "obj: 5.839086895344946 grad_norm: 0.1213188454151857 t: 0.01384128720099999\n",
      "obj: 5.838976153288804 grad_norm: 0.09752219488688799 t: 0.028247524899999984\n",
      "obj: 5.838844848417132 grad_norm: 0.1644883264102654 t: 0.009688901040699992\n",
      "obj: 5.838650373242827 grad_norm: 0.08434602135838447 t: 0.05764800999999997\n",
      "obj: 5.838450096605437 grad_norm: 0.23024935394592455 t: 0.006782230728489994\n",
      "obj: 5.836849945005981 grad_norm: 0.07863534221242319 t: 0.48999999999999994\n",
      "obj: 5.8354315889303106 grad_norm: 0.41340517459557524 t: 0.01384128720099999\n",
      "obj: 5.833614089170212 grad_norm: 0.07687596760405482 t: 0.48999999999999994\n",
      "obj: 5.832563474282943 grad_norm: 0.6853094231112641 t: 0.004747561509942996\n",
      "obj: 5.8324394388456335 grad_norm: 0.08861877929856522 t: 0.028247524899999984\n",
      "obj: 5.832324782539947 grad_norm: 0.12265854717371663 t: 0.01384128720099999\n",
      "obj: 5.832207262453068 grad_norm: 0.09058511272500362 t: 0.028247524899999984\n",
      "obj: 5.832086309400812 grad_norm: 0.12840431163217436 t: 0.01384128720099999\n",
      "obj: 5.831974420557288 grad_norm: 0.09223617708427566 t: 0.028247524899999984\n",
      "obj: 5.831848013388088 grad_norm: 0.13307208511037966 t: 0.01384128720099999\n",
      "obj: 5.8317407140179425 grad_norm: 0.09353754290740351 t: 0.028247524899999984\n",
      "obj: 5.831609897044942 grad_norm: 0.13667375259379766 t: 0.01384128720099999\n",
      "obj: 5.831506179906211 grad_norm: 0.09451292481646224 t: 0.028247524899999984\n",
      "obj: 5.831371988397176 grad_norm: 0.13934599565659084 t: 0.01384128720099999\n",
      "obj: 5.831271266398173 grad_norm: 0.09521691342737612 t: 0.019773267429999988\n",
      "obj: 5.831169490654782 grad_norm: 0.10437292682407408 t: 0.019773267429999988\n",
      "obj: 5.8310735371103 grad_norm: 0.12114954376694007 t: 0.01384128720099999\n",
      "obj: 5.830969476235967 grad_norm: 0.09654802834686685 t: 0.019773267429999988\n",
      "obj: 5.8308782020071455 grad_norm: 0.10924651339703934 t: 0.01384128720099999\n",
      "obj: 5.830764421428944 grad_norm: 0.09032920537062657 t: 0.028247524899999984\n",
      "obj: 5.830655816097361 grad_norm: 0.14448291191275253 t: 0.009688901040699992\n",
      "obj: 5.830442776136175 grad_norm: 0.07957594264797843 t: 0.08235429999999996\n",
      "obj: 5.830151130762637 grad_norm: 0.2927795345451825 t: 0.006782230728489994\n",
      "obj: 5.8249455748993535 grad_norm: 0.07497544901418868 t: 1.0\n",
      "obj: 5.824538043083074 grad_norm: 0.25382288805547565 t: 0.01384128720099999\n",
      "obj: 5.824449622709619 grad_norm: 0.10904770929737348 t: 0.01384128720099999\n",
      "obj: 5.8243441479739 grad_norm: 0.08973527180896969 t: 0.028247524899999984\n",
      "obj: 5.824235124578729 grad_norm: 0.1466684177739368 t: 0.009688901040699992\n",
      "obj: 5.824037275934534 grad_norm: 0.07872712108418582 t: 0.05764800999999997\n",
      "obj: 5.823876677888073 grad_norm: 0.19790236855023322 t: 0.009688901040699992\n",
      "obj: 5.823763482589141 grad_norm: 0.08715861805571623 t: 0.028247524899999984\n",
      "obj: 5.823663951012391 grad_norm: 0.13631395550777864 t: 0.009688901040699992\n",
      "obj: 5.823427627772299 grad_norm: 0.07745331199076579 t: 0.08235429999999996\n",
      "obj: 5.823179571743608 grad_norm: 0.26562277461097406 t: 0.006782230728489994\n",
      "obj: 5.819342276592463 grad_norm: 0.07373565248916399 t: 1.0\n",
      "obj: 5.817739804262584 grad_norm: 0.4340713934101647 t: 0.01384128720099999\n",
      "obj: 5.817503357977442 grad_norm: 0.07648603787551347 t: 0.08235429999999996\n",
      "obj: 5.817266300561793 grad_norm: 0.25876974741088193 t: 0.006782230728489994\n",
      "obj: 5.813795690412088 grad_norm: 0.07298625403517266 t: 1.0\n",
      "obj: 5.81194471969028 grad_norm: 0.45777863354080456 t: 0.01384128720099999\n",
      "obj: 5.811845135669458 grad_norm: 0.08825714816232695 t: 0.028247524899999984\n",
      "obj: 5.811738875857227 grad_norm: 0.14551197354764253 t: 0.009688901040699992\n",
      "obj: 5.811556423296322 grad_norm: 0.07742201556033092 t: 0.05764800999999997\n",
      "obj: 5.8113956559293785 grad_norm: 0.199957079597022 t: 0.009688901040699992\n",
      "obj: 5.811291570183301 grad_norm: 0.08678072362405227 t: 0.028247524899999984\n",
      "obj: 5.811190729330488 grad_norm: 0.1395703776052635 t: 0.009688901040699992\n",
      "obj: 5.810991248344738 grad_norm: 0.07665872783609284 t: 0.05764800999999997\n",
      "obj: 5.810846022345744 grad_norm: 0.18532249796961894 t: 0.009688901040699992\n",
      "obj: 5.810732693250662 grad_norm: 0.08376405487767305 t: 0.028247524899999984\n",
      "obj: 5.810640856450598 grad_norm: 0.1270391356346619 t: 0.01384128720099999\n",
      "obj: 5.8105480288321 grad_norm: 0.09906687827293886 t: 0.019773267429999988\n",
      "obj: 5.810460378649646 grad_norm: 0.11552684055572365 t: 0.01384128720099999\n",
      "obj: 5.810365395707713 grad_norm: 0.09267544507318011 t: 0.019773267429999988\n",
      "obj: 5.81028138518081 grad_norm: 0.10559196909228143 t: 0.01384128720099999\n",
      "obj: 5.8101798678705645 grad_norm: 0.08739996187653279 t: 0.028247524899999984\n",
      "obj: 5.810076582306583 grad_norm: 0.142390201666968 t: 0.009688901040699992\n",
      "obj: 5.809886197987124 grad_norm: 0.07693577550790318 t: 0.05764800999999997\n",
      "obj: 5.809733551282888 grad_norm: 0.19249812858608664 t: 0.009688901040699992\n",
      "obj: 5.809625084547371 grad_norm: 0.08514456938748506 t: 0.028247524899999984\n",
      "obj: 5.80953003108979 grad_norm: 0.1331429858493388 t: 0.009688901040699992\n",
      "obj: 5.809305694481021 grad_norm: 0.07583498363227668 t: 0.08235429999999996\n",
      "obj: 5.809065918611014 grad_norm: 0.261046925978789 t: 0.006782230728489994\n",
      "obj: 5.805429291287745 grad_norm: 0.07221555632982385 t: 1.0\n",
      "obj: 5.803832094740443 grad_norm: 0.43404132580587396 t: 0.01384128720099999\n",
      "obj: 5.803576915601695 grad_norm: 0.07487805462811868 t: 0.08235429999999996\n",
      "obj: 5.803373106539887 grad_norm: 0.23637798907057428 t: 0.006782230728489994\n",
      "obj: 5.801166281951157 grad_norm: 0.07217533143009851 t: 1.0\n",
      "obj: 5.798301195263431 grad_norm: 0.5351099761508723 t: 0.019773267429999988\n",
      "obj: 5.7981200187781425 grad_norm: 0.22001323374896242 t: 0.006782230728489994\n",
      "obj: 5.796645090216538 grad_norm: 0.07214259076495348 t: 0.7\n",
      "obj: 5.794753465257983 grad_norm: 0.48172530979851313 t: 0.019773267429999988\n",
      "obj: 5.794424330464135 grad_norm: 0.3183960458121555 t: 0.006782230728489994\n",
      "obj: 5.790310724357382 grad_norm: 0.07129846417616684 t: 1.0\n",
      "obj: 5.789345522801863 grad_norm: 0.651129129724064 t: 0.004747561509942996\n",
      "obj: 5.789246489110278 grad_norm: 0.08663171214436503 t: 0.028247524899999984\n",
      "obj: 5.789135318619115 grad_norm: 0.12611528619240436 t: 0.01384128720099999\n",
      "obj: 5.789045904496252 grad_norm: 0.08978453368876699 t: 0.019773267429999988\n",
      "obj: 5.788956512429007 grad_norm: 0.09915430930029444 t: 0.019773267429999988\n",
      "obj: 5.788870504064688 grad_norm: 0.11648107585609092 t: 0.01384128720099999\n",
      "obj: 5.788778955408153 grad_norm: 0.09292648792936017 t: 0.019773267429999988\n",
      "obj: 5.788696420858003 grad_norm: 0.10677535863612411 t: 0.01384128720099999\n",
      "obj: 5.788602898989677 grad_norm: 0.08768223615601475 t: 0.028247524899999984\n",
      "obj: 5.788496717495864 grad_norm: 0.14680192248222287 t: 0.009688901040699992\n",
      "obj: 5.788332513303751 grad_norm: 0.07672521069631152 t: 0.05764800999999997\n",
      "obj: 5.788165647505253 grad_norm: 0.2070290095916465 t: 0.009688901040699992\n",
      "obj: 5.788072543381074 grad_norm: 0.0877761476503278 t: 0.028247524899999984\n",
      "obj: 5.78796598344275 grad_norm: 0.14723363100301046 t: 0.009688901040699992\n",
      "obj: 5.787803376422318 grad_norm: 0.07677077160680104 t: 0.05764800999999997\n",
      "obj: 5.787635254167094 grad_norm: 0.20820366942118027 t: 0.009688901040699992\n",
      "obj: 5.787543126776332 grad_norm: 0.08804033819340559 t: 0.028247524899999984\n",
      "obj: 5.7874355521519405 grad_norm: 0.14835649037389173 t: 0.009688901040699992\n",
      "obj: 5.787276843123318 grad_norm: 0.07691099554481298 t: 0.05764800999999997\n",
      "obj: 5.7871075822491695 grad_norm: 0.21120765420846047 t: 0.006782230728489994\n",
      "obj: 5.785885268813857 grad_norm: 0.07186137964959577 t: 0.48999999999999994\n",
      "obj: 5.784570996733924 grad_norm: 0.4043500627854818 t: 0.01384128720099999\n",
      "obj: 5.7828133641312185 grad_norm: 0.07154574550059871 t: 0.7\n",
      "obj: 5.780994520565593 grad_norm: 0.45540430422566586 t: 0.01384128720099999\n",
      "obj: 5.780891647521574 grad_norm: 0.0843103417677359 t: 0.028247524899999984\n",
      "obj: 5.780797469997273 grad_norm: 0.13356787540342152 t: 0.009688901040699992\n",
      "obj: 5.780599296805274 grad_norm: 0.07491372179668658 t: 0.08235429999999996\n",
      "obj: 5.780348169037384 grad_norm: 0.2693163618229334 t: 0.006782230728489994\n",
      "obj: 5.776246496577789 grad_norm: 0.0709323232517194 t: 1.0\n",
      "obj: 5.775281074448685 grad_norm: 0.3604858669890252 t: 0.01384128720099999\n",
      "obj: 5.775175781424145 grad_norm: 0.08369660657546994 t: 0.028247524899999984\n",
      "obj: 5.775073277717665 grad_norm: 0.1184449575878681 t: 0.01384128720099999\n",
      "obj: 5.77497836505044 grad_norm: 0.0871528974676319 t: 0.028247524899999984\n",
      "obj: 5.774865345739843 grad_norm: 0.12826448263568965 t: 0.01384128720099999\n",
      "obj: 5.7747775563020065 grad_norm: 0.09027662818937643 t: 0.019773267429999988\n",
      "obj: 5.774689677265341 grad_norm: 0.10002044251115423 t: 0.019773267429999988\n",
      "obj: 5.774603809119799 grad_norm: 0.11807945713112428 t: 0.01384128720099999\n",
      "obj: 5.774513740788104 grad_norm: 0.09369061761223282 t: 0.019773267429999988\n",
      "obj: 5.774431373569518 grad_norm: 0.10823318498337121 t: 0.01384128720099999\n",
      "obj: 5.77434252304457 grad_norm: 0.08831548385398166 t: 0.028247524899999984\n",
      "obj: 5.774233316573774 grad_norm: 0.15051375568535497 t: 0.009688901040699992\n",
      "obj: 5.7740859334044385 grad_norm: 0.07693646814325718 t: 0.05764800999999997\n",
      "obj: 5.773908202500693 grad_norm: 0.21781461664348517 t: 0.006782230728489994\n",
      "obj: 5.772590044387807 grad_norm: 0.07142376601214942 t: 0.48999999999999994\n",
      "obj: 5.771397659957838 grad_norm: 0.3901319811650788 t: 0.01384128720099999\n",
      "obj: 5.771108122041701 grad_norm: 0.07405902639720632 t: 0.11764899999999995\n",
      "obj: 5.770768155153822 grad_norm: 0.23639640771867848 t: 0.01384128720099999\n",
      "obj: 5.770685461211548 grad_norm: 0.10958154698325924 t: 0.01384128720099999\n",
      "obj: 5.770593992681067 grad_norm: 0.08900335902769452 t: 0.019773267429999988\n",
      "obj: 5.77051439042415 grad_norm: 0.10089209346623164 t: 0.01384128720099999\n",
      "obj: 5.7704135858760885 grad_norm: 0.08442842567556794 t: 0.028247524899999984\n",
      "obj: 5.770318547330871 grad_norm: 0.13484368497629737 t: 0.009688901040699992\n",
      "obj: 5.770133163189543 grad_norm: 0.07484580922999835 t: 0.08235429999999996\n",
      "obj: 5.7698722631123305 grad_norm: 0.2758638464695417 t: 0.006782230728489994\n",
      "obj: 5.765475794691682 grad_norm: 0.07062409713137342 t: 1.0\n",
      "obj: 5.7648532296403365 grad_norm: 0.3043458497152847 t: 0.01384128720099999\n",
      "obj: 5.764773635982935 grad_norm: 0.10148062286694352 t: 0.01384128720099999\n",
      "obj: 5.764674447683523 grad_norm: 0.08467538591406719 t: 0.028247524899999984\n",
      "obj: 5.764578302833936 grad_norm: 0.1362486215285189 t: 0.009688901040699992\n",
      "obj: 5.764388880927589 grad_norm: 0.0749022419213516 t: 0.05764800999999997\n",
      "obj: 5.764249500995149 grad_norm: 0.1816295036977494 t: 0.009688901040699992\n",
      "obj: 5.764142001658605 grad_norm: 0.08197784033571227 t: 0.028247524899999984\n",
      "obj: 5.76405413939621 grad_norm: 0.12494285657485363 t: 0.01384128720099999\n",
      "obj: 5.763966124891907 grad_norm: 0.09747775249224742 t: 0.019773267429999988\n",
      "obj: 5.763882026577693 grad_norm: 0.11427863641587273 t: 0.01384128720099999\n",
      "obj: 5.7637919156048 grad_norm: 0.09149669733734365 t: 0.019773267429999988\n",
      "obj: 5.7637111391553955 grad_norm: 0.10492564042803543 t: 0.01384128720099999\n",
      "obj: 5.763617813147283 grad_norm: 0.08646148528555227 t: 0.028247524899999984\n",
      "obj: 5.763515100271735 grad_norm: 0.14366614322626994 t: 0.009688901040699992\n",
      "obj: 5.763347639458439 grad_norm: 0.0758067839377821 t: 0.05764800999999997\n",
      "obj: 5.763188915726158 grad_norm: 0.20013516503159748 t: 0.009688901040699992\n",
      "obj: 5.763093588850407 grad_norm: 0.08581801161736081 t: 0.028247524899999984\n",
      "obj: 5.762993222894424 grad_norm: 0.1410618912571163 t: 0.009688901040699992\n",
      "obj: 5.762817924085764 grad_norm: 0.07546259608612292 t: 0.05764800999999997\n",
      "obj: 5.762666218443327 grad_norm: 0.19353197185159318 t: 0.009688901040699992\n",
      "obj: 5.762566362914283 grad_norm: 0.08437116524298197 t: 0.028247524899999984\n",
      "obj: 5.762471246175495 grad_norm: 0.13511637816857722 t: 0.009688901040699992\n",
      "obj: 5.7622791685348504 grad_norm: 0.07473050396535566 t: 0.05764800999999997\n",
      "obj: 5.762142563636019 grad_norm: 0.17894915738129683 t: 0.009688901040699992\n",
      "obj: 5.762033690439989 grad_norm: 0.08143054094027255 t: 0.028247524899999984\n",
      "obj: 5.761946678068065 grad_norm: 0.12274055723540268 t: 0.01384128720099999\n",
      "obj: 5.76185835601708 grad_norm: 0.09620682547716743 t: 0.019773267429999988\n",
      "obj: 5.761775025674572 grad_norm: 0.11232566139720183 t: 0.01384128720099999\n",
      "obj: 5.7616846593797755 grad_norm: 0.09040922785837839 t: 0.019773267429999988\n",
      "obj: 5.761604558158408 grad_norm: 0.10323342457215824 t: 0.01384128720099999\n",
      "obj: 5.761508605611949 grad_norm: 0.0855546867154796 t: 0.028247524899999984\n",
      "obj: 5.761409149104857 grad_norm: 0.1400748692570624 t: 0.009688901040699992\n",
      "obj: 5.761231246591628 grad_norm: 0.07531008128396313 t: 0.05764800999999997\n",
      "obj: 5.761082135470519 grad_norm: 0.1910927398360938 t: 0.009688901040699992\n",
      "obj: 5.7609808045275965 grad_norm: 0.08383219236292128 t: 0.028247524899999984\n",
      "obj: 5.760887577407411 grad_norm: 0.13296790097289007 t: 0.009688901040699992\n",
      "obj: 5.7606930307289925 grad_norm: 0.0744546610408504 t: 0.08235429999999996\n",
      "obj: 5.760444004905733 grad_norm: 0.2681230233460833 t: 0.006782230728489994\n",
      "obj: 5.75644253601183 grad_norm: 0.07048851332164618 t: 1.0\n",
      "obj: 5.755439297407404 grad_norm: 0.3657985143763352 t: 0.01384128720099999\n",
      "obj: 5.755326361989031 grad_norm: 0.0814589696629156 t: 0.04035360699999998\n",
      "obj: 5.755182703441008 grad_norm: 0.1518816213335088 t: 0.01384128720099999\n",
      "obj: 5.755100940129852 grad_norm: 0.09688295594314286 t: 0.019773267429999988\n",
      "obj: 5.755007771678587 grad_norm: 0.10916086946733394 t: 0.01384128720099999\n",
      "obj: 5.754905672162968 grad_norm: 0.08382332196463504 t: 0.028247524899999984\n",
      "obj: 5.75480255908143 grad_norm: 0.11964119072903073 t: 0.01384128720099999\n",
      "obj: 5.754710867273285 grad_norm: 0.0872867671450325 t: 0.028247524899999984\n",
      "obj: 5.754597171982065 grad_norm: 0.12936473748453142 t: 0.01384128720099999\n",
      "obj: 5.754510884402375 grad_norm: 0.09036838801888109 t: 0.019773267429999988\n",
      "obj: 5.754424431967635 grad_norm: 0.10032019327855926 t: 0.019773267429999988\n",
      "obj: 5.754339083160363 grad_norm: 0.11877297227239704 t: 0.01384128720099999\n",
      "obj: 5.754250421630558 grad_norm: 0.09390699310998614 t: 0.019773267429999988\n",
      "obj: 5.7541685993426634 grad_norm: 0.10881472330404797 t: 0.01384128720099999\n",
      "obj: 5.754077993411094 grad_norm: 0.08844092559136608 t: 0.019773267429999988\n",
      "obj: 5.753999227793425 grad_norm: 0.10019822943812866 t: 0.01384128720099999\n",
      "obj: 5.753899082963438 grad_norm: 0.08391046168469848 t: 0.028247524899999984\n",
      "obj: 5.7538053382857255 grad_norm: 0.1337171686277748 t: 0.009688901040699992\n",
      "obj: 5.7536178030018545 grad_norm: 0.07441352114288916 t: 0.08235429999999996\n",
      "obj: 5.753363469755117 grad_norm: 0.27168620702628365 t: 0.006782230728489994\n",
      "obj: 5.749202553888292 grad_norm: 0.07031371467361718 t: 1.0\n",
      "obj: 5.748385458202563 grad_norm: 0.33839108829119413 t: 0.01384128720099999\n",
      "obj: 5.7483000306682035 grad_norm: 0.09106169352093339 t: 0.019773267429999988\n",
      "obj: 5.7482142730878 grad_norm: 0.10131721050075922 t: 0.019773267429999988\n",
      "obj: 5.7481285712401755 grad_norm: 0.12036084218469816 t: 0.01384128720099999\n",
      "obj: 5.748040567272312 grad_norm: 0.09474508501125997 t: 0.019773267429999988\n",
      "obj: 5.747958464752169 grad_norm: 0.11018264336985296 t: 0.01384128720099999\n",
      "obj: 5.747868470983655 grad_norm: 0.08912152857760555 t: 0.019773267429999988\n",
      "obj: 5.747789503316951 grad_norm: 0.10134172556950251 t: 0.01384128720099999\n",
      "obj: 5.747691812884496 grad_norm: 0.08444028838434886 t: 0.028247524899999984\n",
      "obj: 5.747595960567772 grad_norm: 0.13626505739373396 t: 0.009688901040699992\n",
      "obj: 5.747409774594886 grad_norm: 0.07460367097855077 t: 0.05764800999999997\n",
      "obj: 5.7472704198532565 grad_norm: 0.18191902917876512 t: 0.009688901040699992\n",
      "obj: 5.747164500042029 grad_norm: 0.08176446890675769 t: 0.028247524899999984\n",
      "obj: 5.747077177958847 grad_norm: 0.1250772775505108 t: 0.01384128720099999\n",
      "obj: 5.746990161464576 grad_norm: 0.09741430737840812 t: 0.019773267429999988\n",
      "obj: 5.746906620642625 grad_norm: 0.1143438990899628 t: 0.01384128720099999\n",
      "obj: 5.7468174976493325 grad_norm: 0.09138275720583793 t: 0.019773267429999988\n",
      "obj: 5.746737296148574 grad_norm: 0.10492330009388182 t: 0.01384128720099999\n",
      "obj: 5.746645674705168 grad_norm: 0.0863010507087198 t: 0.028247524899999984\n",
      "obj: 5.746543003992842 grad_norm: 0.14395891211144765 t: 0.009688901040699992\n",
      "obj: 5.746379634475242 grad_norm: 0.07555074974674351 t: 0.05764800999999997\n",
      "obj: 5.746220169970115 grad_norm: 0.20112848040148673 t: 0.009688901040699992\n",
      "obj: 5.746126951602141 grad_norm: 0.08578503880166015 t: 0.028247524899999984\n",
      "obj: 5.746026158635939 grad_norm: 0.14187968583598448 t: 0.009688901040699992\n",
      "obj: 5.745856468342661 grad_norm: 0.07527155450239588 t: 0.05764800999999997\n",
      "obj: 5.7457026595262155 grad_norm: 0.19582498191221198 t: 0.009688901040699992\n",
      "obj: 5.74560574503119 grad_norm: 0.08460424524664624 t: 0.028247524899999984\n",
      "obj: 5.74550923564605 grad_norm: 0.13705502489807914 t: 0.009688901040699992\n",
      "obj: 5.745325593324517 grad_norm: 0.07466263509734833 t: 0.05764800999999997\n",
      "obj: 5.745184294145271 grad_norm: 0.18384853740208246 t: 0.009688901040699992\n",
      "obj: 5.745079688707025 grad_norm: 0.08211063775697404 t: 0.028247524899999984\n",
      "obj: 5.744992087941269 grad_norm: 0.12666401007011005 t: 0.009688901040699992\n",
      "obj: 5.744763529090925 grad_norm: 0.07349029151393968 t: 0.08235429999999996\n",
      "obj: 5.744553053935449 grad_norm: 0.24187923357856403 t: 0.006782230728489994\n",
      "obj: 5.742080015604909 grad_norm: 0.07049019665538372 t: 1.0\n",
      "obj: 5.739789728484581 grad_norm: 0.5057184646286258 t: 0.019773267429999988\n",
      "obj: 5.739523068326748 grad_norm: 0.2798284430304831 t: 0.006782230728489994\n",
      "obj: 5.73504165627949 grad_norm: 0.06998927244964016 t: 1.0\n",
      "obj: 5.734594905596585 grad_norm: 0.26600648111799946 t: 0.01384128720099999\n",
      "obj: 5.734514103127545 grad_norm: 0.10768389411452205 t: 0.01384128720099999\n",
      "obj: 5.734424331925437 grad_norm: 0.08765377266989045 t: 0.019773267429999988\n",
      "obj: 5.734345525164229 grad_norm: 0.09913527071799144 t: 0.019773267429999988\n",
      "obj: 5.73425009028842 grad_norm: 0.11225213759897007 t: 0.01384128720099999\n",
      "obj: 5.734152772904807 grad_norm: 0.0845973920852916 t: 0.028247524899999984\n",
      "obj: 5.734047132563779 grad_norm: 0.12254675542476826 t: 0.01384128720099999\n",
      "obj: 5.733960529316148 grad_norm: 0.08795917414673583 t: 0.019773267429999988\n",
      "obj: 5.733874120970134 grad_norm: 0.09710498537173352 t: 0.019773267429999988\n",
      "obj: 5.733791118917503 grad_norm: 0.11396278779102015 t: 0.01384128720099999\n",
      "obj: 5.733702604187097 grad_norm: 0.0910548067085062 t: 0.019773267429999988\n",
      "obj: 5.733622948141983 grad_norm: 0.10451907904927929 t: 0.01384128720099999\n",
      "obj: 5.733531818467619 grad_norm: 0.08596517862653838 t: 0.028247524899999984\n",
      "obj: 5.73342999791611 grad_norm: 0.14324712577069654 t: 0.009688901040699992\n",
      "obj: 5.733266514116847 grad_norm: 0.07523942617484054 t: 0.05764800999999997\n",
      "obj: 5.733109184830301 grad_norm: 0.19932457859736802 t: 0.009688901040699992\n",
      "obj: 5.733015614831294 grad_norm: 0.08518355948458486 t: 0.028247524899999984\n",
      "obj: 5.732916633551448 grad_norm: 0.14008086300034303 t: 0.009688901040699992\n",
      "obj: 5.732743674819588 grad_norm: 0.074824680708798 t: 0.05764800999999997\n",
      "obj: 5.732594809288345 grad_norm: 0.1913274689579495 t: 0.009688901040699992\n",
      "obj: 5.73249582211543 grad_norm: 0.08344352116535327 t: 0.028247524899999984\n",
      "obj: 5.7324031057384826 grad_norm: 0.13292730163844027 t: 0.009688901040699992\n",
      "obj: 5.7322158257940625 grad_norm: 0.07395896053634331 t: 0.08235429999999996\n",
      "obj: 5.731966316583969 grad_norm: 0.2686152462805539 t: 0.006782230728489994\n",
      "obj: 5.728024092835817 grad_norm: 0.06994334074234959 t: 1.0\n",
      "obj: 5.727038741262506 grad_norm: 0.36329854264260536 t: 0.01384128720099999\n",
      "obj: 5.7269338368485805 grad_norm: 0.08171939737329312 t: 0.028247524899999984\n",
      "obj: 5.72683657295541 grad_norm: 0.11438404524441327 t: 0.01384128720099999\n",
      "obj: 5.726741916306729 grad_norm: 0.0852110714258044 t: 0.028247524899999984\n",
      "obj: 5.726634344111366 grad_norm: 0.12448937096048607 t: 0.01384128720099999\n",
      "obj: 5.726548503188011 grad_norm: 0.08848192647617911 t: 0.019773267429999988\n",
      "obj: 5.726462742140174 grad_norm: 0.09787507705395729 t: 0.019773267429999988\n",
      "obj: 5.726379518777767 grad_norm: 0.11520207355597115 t: 0.01384128720099999\n",
      "obj: 5.726291612990494 grad_norm: 0.09167088930911386 t: 0.019773267429999988\n",
      "obj: 5.726211811032312 grad_norm: 0.10554321673418682 t: 0.01384128720099999\n",
      "obj: 5.726123052393736 grad_norm: 0.08643673865760534 t: 0.028247524899999984\n",
      "obj: 5.726019295713362 grad_norm: 0.14551009676957774 t: 0.009688901040699992\n",
      "obj: 5.725864041128653 grad_norm: 0.07541963470991071 t: 0.05764800999999997\n",
      "obj: 5.72570058867465 grad_norm: 0.20512721305572656 t: 0.009688901040699992\n",
      "obj: 5.725611743041798 grad_norm: 0.08639193861039793 t: 0.028247524899999984\n",
      "obj: 5.725508137253557 grad_norm: 0.14535210334819523 t: 0.009688901040699992\n",
      "obj: 5.725352448812732 grad_norm: 0.0753900926785626 t: 0.05764800999999997\n",
      "obj: 5.725189450662392 grad_norm: 0.20471279872089007 t: 0.009688901040699992\n",
      "obj: 5.725100328043166 grad_norm: 0.08628828110464544 t: 0.028247524899999984\n",
      "obj: 5.724997089336899 grad_norm: 0.144955591096345 t: 0.009688901040699992\n",
      "obj: 5.724840207743207 grad_norm: 0.07532860272687811 t: 0.05764800999999997\n",
      "obj: 5.724678329198305 grad_norm: 0.20368053595777874 t: 0.009688901040699992\n",
      "obj: 5.7245884728298195 grad_norm: 0.08604263270808919 t: 0.028247524899999984\n",
      "obj: 5.724486121543475 grad_norm: 0.14398278385640975 t: 0.009688901040699992\n",
      "obj: 5.724326241550257 grad_norm: 0.07519083571385744 t: 0.05764800999999997\n",
      "obj: 5.72416706941632 grad_norm: 0.20116701437951487 t: 0.009688901040699992\n",
      "obj: 5.724075410736842 grad_norm: 0.08546228012252859 t: 0.028247524899999984\n",
      "obj: 5.723975166833831 grad_norm: 0.1416457164452709 t: 0.009688901040699992\n",
      "obj: 5.723808179329833 grad_norm: 0.07487782696628802 t: 0.05764800999999997\n",
      "obj: 5.723655352182282 grad_norm: 0.19521205784151272 t: 0.009688901040699992\n",
      "obj: 5.72355955435064 grad_norm: 0.0841367890757648 t: 0.028247524899999984\n",
      "obj: 5.723464099078896 grad_norm: 0.1362373916827342 t: 0.009688901040699992\n",
      "obj: 5.723281607817612 grad_norm: 0.07419888838366985 t: 0.05764800999999997\n",
      "obj: 5.723142687939502 grad_norm: 0.18185500488746126 t: 0.009688901040699992\n",
      "obj: 5.723038438527941 grad_norm: 0.08137722083489152 t: 0.028247524899999984\n",
      "obj: 5.722951958522595 grad_norm: 0.12473753303378116 t: 0.01384128720099999\n",
      "obj: 5.7228660834269265 grad_norm: 0.09700798271278488 t: 0.019773267429999988\n",
      "obj: 5.722783428787362 grad_norm: 0.11388211560375729 t: 0.01384128720099999\n",
      "obj: 5.7226954395258725 grad_norm: 0.09090973478059415 t: 0.019773267429999988\n",
      "obj: 5.722616154022972 grad_norm: 0.10437341257205385 t: 0.01384128720099999\n",
      "obj: 5.722525702095935 grad_norm: 0.08578510174961207 t: 0.028247524899999984\n",
      "obj: 5.722424237877193 grad_norm: 0.14303121282887124 t: 0.009688901040699992\n",
      "obj: 5.722261691935916 grad_norm: 0.07503239100976253 t: 0.05764800999999997\n",
      "obj: 5.722105167495186 grad_norm: 0.19871485174067538 t: 0.009688901040699992\n",
      "obj: 5.722011893471382 grad_norm: 0.0848818047443293 t: 0.028247524899999984\n",
      "obj: 5.721913704120256 grad_norm: 0.13937041879211423 t: 0.009688901040699992\n",
      "obj: 5.721740281774851 grad_norm: 0.07455645003107202 t: 0.05764800999999997\n",
      "obj: 5.721593473319853 grad_norm: 0.18950887428563581 t: 0.009688901040699992\n",
      "obj: 5.721494041032616 grad_norm: 0.08289544031196511 t: 0.028247524899999984\n",
      "obj: 5.721402973029058 grad_norm: 0.13119309928689413 t: 0.009688901040699992\n",
      "obj: 5.721207036939843 grad_norm: 0.07358304422765044 t: 0.08235429999999996\n",
      "obj: 5.72096878133577 grad_norm: 0.26113866373686256 t: 0.006782230728489994\n",
      "obj: 5.7174653012035055 grad_norm: 0.0698292048203371 t: 1.0\n",
      "obj: 5.716061133656952 grad_norm: 0.41433128118987295 t: 0.01384128720099999\n",
      "obj: 5.711243211810941 grad_norm: 0.06951187050819331 t: 1.0\n",
      "obj: 5.7111547696966785 grad_norm: 0.08671756091537589 t: 0.028247524899999984\n",
      "obj: 5.711042395807968 grad_norm: 0.12903567572783955 t: 0.01384128720099999\n",
      "obj: 5.710958210332423 grad_norm: 0.08969985779504494 t: 0.019773267429999988\n",
      "obj: 5.710873811483426 grad_norm: 0.09963632987682051 t: 0.019773267429999988\n",
      "obj: 5.7107900346964025 grad_norm: 0.11799820150748098 t: 0.01384128720099999\n",
      "obj: 5.7107034091478495 grad_norm: 0.09308310638603814 t: 0.019773267429999988\n",
      "obj: 5.710623224244203 grad_norm: 0.1078546970093945 t: 0.01384128720099999\n",
      "obj: 5.710534646891778 grad_norm: 0.08752277077849713 t: 0.019773267429999988\n",
      "obj: 5.710457557785379 grad_norm: 0.09911487878873221 t: 0.01384128720099999\n",
      "obj: 5.710359485942395 grad_norm: 0.08293901879622315 t: 0.028247524899999984\n",
      "obj: 5.71026796372039 grad_norm: 0.1319059226820765 t: 0.009688901040699992\n",
      "obj: 5.710078765272992 grad_norm: 0.07348350430197442 t: 0.08235429999999996\n",
      "obj: 5.709836077125264 grad_norm: 0.2641585126289167 t: 0.006782230728489994\n",
      "obj: 5.706207806878822 grad_norm: 0.06960791718070629 t: 1.0\n",
      "obj: 5.70495639141499 grad_norm: 0.3970783503965369 t: 0.01384128720099999\n",
      "obj: 5.704406229714976 grad_norm: 0.07105193040664359 t: 0.24009999999999992\n",
      "obj: 5.703754903529026 grad_norm: 0.30980345371511464 t: 0.01384128720099999\n",
      "obj: 5.70367755753163 grad_norm: 0.09883869822347668 t: 0.019773267429999988\n",
      "obj: 5.703583061172243 grad_norm: 0.11195422672692927 t: 0.01384128720099999\n",
      "obj: 5.703487639716218 grad_norm: 0.08411064090933432 t: 0.028247524899999984\n",
      "obj: 5.703383164864181 grad_norm: 0.12204009149015974 t: 0.01384128720099999\n",
      "obj: 5.703297901031179 grad_norm: 0.08739864122202352 t: 0.019773267429999988\n",
      "obj: 5.70321280370206 grad_norm: 0.09648071867438644 t: 0.019773267429999988\n",
      "obj: 5.703130937341618 grad_norm: 0.11317022555117533 t: 0.01384128720099999\n",
      "obj: 5.703043724692265 grad_norm: 0.09033662099078713 t: 0.019773267429999988\n",
      "obj: 5.702965251062235 grad_norm: 0.10360234742990372 t: 0.01384128720099999\n",
      "obj: 5.70287505064857 grad_norm: 0.08519491489362079 t: 0.028247524899999984\n",
      "obj: 5.702775226308565 grad_norm: 0.14150193107667292 t: 0.009688901040699992\n",
      "obj: 5.702610645520382 grad_norm: 0.07452158545692794 t: 0.05764800999999997\n",
      "obj: 5.702458711243459 grad_norm: 0.1946214344509826 t: 0.009688901040699992\n",
      "obj: 5.702363819910968 grad_norm: 0.08368782386122259 t: 0.028247524899999984\n",
      "obj: 5.702269417833055 grad_norm: 0.13536419638102543 t: 0.009688901040699992\n",
      "obj: 5.702087428778598 grad_norm: 0.0737559682556997 t: 0.05764800999999997\n",
      "obj: 5.701951127057209 grad_norm: 0.17955876753347214 t: 0.009688901040699992\n",
      "obj: 5.701846876386134 grad_norm: 0.08060715656305185 t: 0.028247524899999984\n",
      "obj: 5.701761745539771 grad_norm: 0.12252254337980263 t: 0.01384128720099999\n",
      "obj: 5.701676404237026 grad_norm: 0.09555069967828199 t: 0.019773267429999988\n",
      "obj: 5.701595085199623 grad_norm: 0.1117385557075709 t: 0.01384128720099999\n",
      "obj: 5.701507666304264 grad_norm: 0.08953885470119761 t: 0.019773267429999988\n",
      "obj: 5.701429673711747 grad_norm: 0.10235807422899551 t: 0.01384128720099999\n",
      "obj: 5.701337529279356 grad_norm: 0.08452943850325993 t: 0.028247524899999984\n",
      "obj: 5.701240075509302 grad_norm: 0.13885798187942033 t: 0.009688901040699992\n",
      "obj: 5.701067938847664 grad_norm: 0.07416341094021126 t: 0.05764800999999997\n",
      "obj: 5.700922940456504 grad_norm: 0.18802288518709948 t: 0.009688901040699992\n",
      "obj: 5.70082384243933 grad_norm: 0.08227340611629613 t: 0.028247524899999984\n",
      "obj: 5.700734431723243 grad_norm: 0.12957822405130567 t: 0.009688901040699992\n",
      "obj: 5.70053261199218 grad_norm: 0.07307401053267515 t: 0.08235429999999996\n",
      "obj: 5.700304771856136 grad_norm: 0.25414119148144243 t: 0.006782230728489994\n",
      "obj: 5.6972790741560955 grad_norm: 0.06956813578812526 t: 1.0\n",
      "obj: 5.695456632214852 grad_norm: 0.45559504250372923 t: 0.01384128720099999\n",
      "obj: 5.695362473713745 grad_norm: 0.08368687885914838 t: 0.028247524899999984\n",
      "obj: 5.695267898304203 grad_norm: 0.13566768859639192 t: 0.009688901040699992\n",
      "obj: 5.695087618968466 grad_norm: 0.07368182571692372 t: 0.05764800999999997\n",
      "obj: 5.694950757615685 grad_norm: 0.1801904198509608 t: 0.009688901040699992\n",
      "obj: 5.694847288646959 grad_norm: 0.08062146987220997 t: 0.028247524899999984\n",
      "obj: 5.694762199073618 grad_norm: 0.12291729650074851 t: 0.01384128720099999\n",
      "obj: 5.69467723931561 grad_norm: 0.09570987960385294 t: 0.019773267429999988\n",
      "obj: 5.694596003852994 grad_norm: 0.11201732582261446 t: 0.01384128720099999\n",
      "obj: 5.694508950871586 grad_norm: 0.08962542647962253 t: 0.019773267429999988\n",
      "obj: 5.694431079021384 grad_norm: 0.10253631075536228 t: 0.01384128720099999\n",
      "obj: 5.694339751763982 grad_norm: 0.08455632529764447 t: 0.028247524899999984\n",
      "obj: 5.6942420263147 grad_norm: 0.13926703370053647 t: 0.009688901040699992\n",
      "obj: 5.694071936604706 grad_norm: 0.07410455821626925 t: 0.05764800999999997\n",
      "obj: 5.6939260799346005 grad_norm: 0.18892509717279954 t: 0.009688901040699992\n",
      "obj: 5.6938279601596475 grad_norm: 0.08235300466160649 t: 0.028247524899999984\n",
      "obj: 5.693738090108549 grad_norm: 0.13022660736555655 t: 0.009688901040699992\n",
      "obj: 5.69354148313945 grad_norm: 0.07303479790623031 t: 0.08235429999999996\n",
      "obj: 5.693309798846113 grad_norm: 0.256786196041433 t: 0.006782230728489994\n",
      "obj: 5.690160041801265 grad_norm: 0.06942256642752907 t: 1.0\n",
      "obj: 5.688472415221694 grad_norm: 0.44300151143351457 t: 0.01384128720099999\n",
      "obj: 5.688339611611406 grad_norm: 0.07617017853958163 t: 0.04035360699999998\n",
      "obj: 5.688233239459592 grad_norm: 0.14891856894276975 t: 0.009688901040699992\n",
      "obj: 5.6880939906957835 grad_norm: 0.07529381710013795 t: 0.05764800999999997\n",
      "obj: 5.6879226057315195 grad_norm: 0.21353518069009705 t: 0.006782230728489994\n",
      "obj: 5.686805863620043 grad_norm: 0.06993178393837693 t: 0.48999999999999994\n",
      "obj: 5.685521907544793 grad_norm: 0.40076593749545497 t: 0.01384128720099999\n",
      "obj: 5.6845264311017285 grad_norm: 0.06999354284556566 t: 0.48999999999999994\n",
      "obj: 5.683123294360957 grad_norm: 0.4140630752772284 t: 0.01384128720099999\n",
      "obj: 5.678433583809295 grad_norm: 0.06896772961371425 t: 1.0\n",
      "obj: 5.678328380082822 grad_norm: 0.14777758905411087 t: 0.009688901040699992\n",
      "obj: 5.678186420866336 grad_norm: 0.07498072487508572 t: 0.05764800999999997\n",
      "obj: 5.678019320252195 grad_norm: 0.21029221425524125 t: 0.006782230728489994\n",
      "obj: 5.676971957812254 grad_norm: 0.06982236985568249 t: 0.48999999999999994\n",
      "obj: 5.6756293113362535 grad_norm: 0.40736740901222407 t: 0.01384128720099999\n",
      "obj: 5.6720679166390715 grad_norm: 0.0690425244857331 t: 1.0\n",
      "obj: 5.6708286763957485 grad_norm: 0.39546998852059023 t: 0.01384128720099999\n",
      "obj: 5.67033259640081 grad_norm: 0.07062078123835276 t: 0.24009999999999992\n",
      "obj: 5.66964504129485 grad_norm: 0.3163137725711282 t: 0.01384128720099999\n",
      "obj: 5.6695674189777 grad_norm: 0.09613754379107668 t: 0.019773267429999988\n",
      "obj: 5.669476741820297 grad_norm: 0.1084537787397504 t: 0.01384128720099999\n",
      "obj: 5.669380092138777 grad_norm: 0.08251121860018829 t: 0.028247524899999984\n",
      "obj: 5.669280037799957 grad_norm: 0.11837222720987735 t: 0.01384128720099999\n",
      "obj: 5.669192976909849 grad_norm: 0.08577045857621987 t: 0.028247524899999984\n",
      "obj: 5.669083146029671 grad_norm: 0.12745813623565602 t: 0.01384128720099999\n",
      "obj: 5.66900042628284 grad_norm: 0.08864155263669644 t: 0.019773267429999988\n",
      "obj: 5.6689174947566086 grad_norm: 0.09833588431331335 t: 0.019773267429999988\n",
      "obj: 5.668835436069612 grad_norm: 0.1161497601546733 t: 0.01384128720099999\n",
      "obj: 5.668750272882484 grad_norm: 0.09165714681365514 t: 0.019773267429999988\n",
      "obj: 5.6686718790161 grad_norm: 0.10584287721813851 t: 0.01384128720099999\n",
      "obj: 5.668587911506811 grad_norm: 0.08605282379632682 t: 0.028247524899999984\n",
      "obj: 5.668484142983739 grad_norm: 0.14633502099102405 t: 0.009688901040699992\n",
      "obj: 5.668338529251979 grad_norm: 0.0746297470224397 t: 0.05764800999999997\n",
      "obj: 5.668176661702595 grad_norm: 0.20627582545836526 t: 0.006782230728489994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.23601538, -3.98089986,  3.56012922,  4.02122149,  0.07035218,\n",
       "        0.07020347,  0.07000234,  0.07011684])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent_backtracking(func, grad_f, x0, alfa=0.4, beta=0.7, max_iter=500, tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38c8e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "X = -(np.random.lognormal(0,1,size= 5))\n",
    "a = 0.01\n",
    "b = 2\n",
    "alpha = 0.5\n",
    "r = 0.1\n",
    "para = [a,b,alpha,r]\n",
    "f = np.zeros(len(X)) + 1/len(X)\n",
    "mu = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7cee3dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[obj,x_s1, x_s2, x_s3] = kl_cvar_ball(alpha,X,f,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "53f6de3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0519835394916175 [-2.58237859] [-1.5472973] [9.22932021]\n"
     ]
    }
   ],
   "source": [
    "print(obj,x_s1,x_s2,x_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "bd8134f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.68408509]\n",
      "[2.97984648]\n",
      "[2.97984601]\n",
      "[2.97984601]\n",
      "[2.97984601]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(x_s3*(kl_c((np.maximum(1/alpha*(x_s2-X[i]),0)-x_s1)/x_s3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7895f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def newton_optimization(f, grad_f, hessian_f, x0,mu, tol=1e-6, max_iter=100, alfa=0.5, beta=0.5):\n",
    "    x = x0\n",
    "    for iteration in range(max_iter):\n",
    "        gradient = grad_f(x,mu)\n",
    "        hessian = hessian_f(x,mu)\n",
    "        if np.linalg.norm(gradient) < tol:\n",
    "            print(f\"Converged after {iteration} iterations\")\n",
    "            return x\n",
    "\n",
    "        step = np.linalg.solve(hessian, -gradient)\n",
    "\n",
    "        # Backtracking line search\n",
    "        t = 1.0\n",
    "        while f(x + t * step,mu) > f(x,mu) + alfa * t * np.dot(gradient, step):\n",
    "            t *= beta\n",
    "        print('x', x)\n",
    "        print('tstep', t*step)\n",
    "\n",
    "        x = x + t * step\n",
    "        print('obj:', f(x,mu))\n",
    "\n",
    "    return x\n",
    "\n",
    "# Example usage:\n",
    "def KL_obj_bar(x,mu):\n",
    "    the1 = x[0]\n",
    "    the2 = x[1]\n",
    "    lbda = x[2]\n",
    "    N = len(X)\n",
    "    som = 0\n",
    "    sb_1 = 0\n",
    "    for i in range(3,N+3):\n",
    "        som = som + lbda * kl_c((x[i]+the1)/lbda)\n",
    "        sb_1 = sb_1 +log_bar(x[i]-1/alpha * (x[1]-X[i-3])) + log_bar(x[i])\n",
    "    return(-the1-the2+lbda*r+som/N +mu*sb_1+mu*log_bar(x[2]))\n",
    "\n",
    "def KL_grad_bar(x,mu):\n",
    "        # Replace this with the gradient of your actual function\n",
    "    the1 = x[0]\n",
    "    the2 = x[1]\n",
    "    lbda = x[2]\n",
    "    N = len(X)\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    sb1 = 0\n",
    "    grad = np.zeros(N+3) \n",
    "    for i in range(3,N+3):\n",
    "        grad[i] = d_kl_c((x[i]+the1)/lbda)/N-mu/(x[i]-1/alpha*(x[1]-X[i-3]))-mu/x[i]\n",
    "        s1 = s1 + d_kl_c((x[i]+the1)/lbda)/N\n",
    "        s2 = s2 + kl_c((x[i]+the1)/lbda) - d_kl_c((x[i]+the1)/lbda)*((x[i]+the1)/lbda)\n",
    "        sb1 = sb1 + mu/(alpha*x[i]-x[1]+X[i-3])\n",
    "    grad[1] = -1 + sb1\n",
    "    grad[0] = -1 + s1\n",
    "    grad[2] = r + s2/N - mu/lbda\n",
    "        \n",
    "    return(grad)\n",
    "\n",
    "def KL_hessian_bar(x,mu):\n",
    "    t1 = x[0]\n",
    "    t2 = x[1]\n",
    "    lbda = x[2]\n",
    "    N = len(X)\n",
    "    s1 = 0\n",
    "    s2 = 0\n",
    "    s3 = 0\n",
    "    s_vec = x[3:(N+3)]\n",
    "    a = 1\n",
    "    b = 1\n",
    "    H = np.zeros((N+3,N+3))\n",
    "    H[0,0] = kl_d11(t1,s_vec,lbda,a,b,N)\n",
    "    H[2,2] = kl_dll(t1,s_vec,lbda,a,b,N) + mu/lbda**2\n",
    "    H[2,0] = kl_d1dl(t1,s_vec,lbda,a,b,N)\n",
    "    H[0,2] = H[2,0]\n",
    "    for i in range(3,N+3):\n",
    "        s2 = s2 + 1/(alpha**2*(x[i]-1/alpha*(t2-X[i-3]))**2)\n",
    "        H[i,0] = kl_d1ds(t1,x[i],lbda,a,b,N)\n",
    "        H[0,i] = H[i,0]\n",
    "        H[i,2] = kl_dsdl(t1,x[i],lbda,a,b,N)\n",
    "        H[2,i] = H[i,2]\n",
    "        H[i,i] = kl_dss(t1,x[i],lbda,a,b,N)+mu/((x[i]-1/alpha*(t2-X[i-3]))**2)+mu/x[i]**2\n",
    "\n",
    "    H[1,1] = s2*mu\n",
    "    return(H)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2cf41346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [-4, -5.981243403948075, 1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "tstep [ 3.69470691e+00  5.98293526e-04 -9.09789793e-01 -4.83391559e-07\n",
      " -2.98584135e-04 -2.98894145e-04 -2.99394758e-04 -2.99096871e-04]\n",
      "obj: 6.283428452665556\n",
      "x [-0.30529309 -5.98064511  0.09021021  0.09999952  0.09970142  0.09970111\n",
      "  0.09970061  0.0997009 ]\n",
      "tstep [ 0.23412204  0.01323936 -0.07660986 -0.00053226 -0.00644687 -0.00645247\n",
      " -0.00646151 -0.00645613]\n",
      "obj: 6.1976863150464165\n",
      "x [-0.07117105 -5.96740575  0.01360034  0.09946725  0.09325455  0.09324864\n",
      "  0.09323909  0.09324477]\n",
      "tstep [-0.01089911  0.02409673 -0.01074593 -0.0141356  -0.00958617 -0.00958166\n",
      " -0.00957437 -0.00957871]\n",
      "obj: 6.164979904350779\n",
      "x [-8.20701645e-02 -5.94330902e+00  2.85441305e-03  8.53316568e-02\n",
      "  8.36683787e-02  8.36669811e-02  8.36647231e-02  8.36660668e-02]\n",
      "tstep [-0.00307342 -0.00251053  0.00264563  0.00566889  0.00265306  0.00265142\n",
      "  0.00264878  0.00265035]\n",
      "obj: 6.154995920620431\n",
      "x [-8.51435873e-02 -5.94581955e+00  5.50003924e-03  9.10005481e-02\n",
      "  8.63214351e-02  8.63184041e-02  8.63135067e-02  8.63164213e-02]\n",
      "tstep [ 1.65037036e-03 -3.43968321e-06  5.44391845e-03  3.52901281e-03\n",
      " -3.28991999e-03 -3.29351338e-03 -3.29932098e-03 -3.29586447e-03]\n",
      "obj: 6.146891341278467\n",
      "x [-0.08349322 -5.94582299  0.01094396  0.09452956  0.08303152  0.08302489\n",
      "  0.08301419  0.08302056]\n",
      "tstep [ 0.00588587  0.0020733   0.01123893  0.00365879 -0.00957287 -0.00957964\n",
      " -0.00959057 -0.00958406]\n",
      "obj: 6.138080106662707\n",
      "x [-0.07760735 -5.94374969  0.02218289  0.09818835  0.07345865  0.07344525\n",
      "  0.07342361  0.07343649]\n",
      "tstep [ 0.00512362  0.00174977  0.02032783  0.00802246 -0.01022045 -0.01022785\n",
      " -0.01023979 -0.01023269]\n",
      "obj: 6.130109067807035\n",
      "x [-0.07248373 -5.94199992  0.04251072  0.1062108   0.06323819  0.0632174\n",
      "  0.06318382  0.0632038 ]\n",
      "tstep [ 0.0007054   0.00520049  0.0280098   0.00973271 -0.00435484 -0.0043569\n",
      " -0.00436019 -0.00435824]\n",
      "obj: 6.123427494961715\n",
      "x [-0.07177833 -5.93679943  0.07052052  0.11594351  0.05888335  0.0588605\n",
      "  0.05882363  0.05884557]\n",
      "tstep [-0.00233466  0.00462652  0.03312532  0.01035899 -0.00084096 -0.00084193\n",
      " -0.00084348 -0.00084256]\n",
      "obj: 6.118763881198956\n",
      "x [-0.07411299 -5.93217291  0.10364583  0.12630251  0.05804239  0.05801857\n",
      "  0.05798016  0.05800301]\n",
      "tstep [-3.02647719e-03  5.58788076e-03  2.88441564e-02  9.70192299e-03\n",
      " -5.25095108e-05 -5.34051855e-05 -5.48343206e-05 -5.39864787e-05]\n",
      "obj: 6.11540944370716\n",
      "x [-0.07713946 -5.92658503  0.13248999  0.13600443  0.05798988  0.05796516\n",
      "  0.05792532  0.05794902]\n",
      "tstep [-0.00309827  0.00431982  0.01621159  0.00948341  0.00034574  0.00034497\n",
      "  0.00034374  0.00034447]\n",
      "obj: 6.112995675152969\n",
      "x [-0.08023773 -5.92226521  0.14870159  0.14548784  0.05833562  0.05831013\n",
      "  0.05826906  0.05829349]\n",
      "tstep [-0.00271896  0.00503237  0.00840333  0.00858022  0.00040679  0.00040611\n",
      "  0.00040503  0.00040567]\n",
      "obj: 6.110659477481656\n",
      "x [-0.08295669 -5.91723284  0.15710492  0.15406807  0.05874242  0.05871624\n",
      "  0.05867409  0.05869916]\n",
      "tstep [-0.00269632  0.00380197  0.00756648  0.00854129  0.0004032   0.0004025\n",
      "  0.00040139  0.00040205]\n",
      "obj: 6.108700418515738\n",
      "x [-0.08565302 -5.91343087  0.1646714   0.16260935  0.05914562  0.05911875\n",
      "  0.05907548  0.05910121]\n",
      "tstep [-0.00242549  0.00456595  0.0069606   0.00772239  0.00033339  0.00033279\n",
      "  0.00033183  0.0003324 ]\n",
      "obj: 6.106722628853643\n",
      "x [-0.0880785  -5.90886492  0.171632    0.17033175  0.05947901  0.05945153\n",
      "  0.05940731  0.0594336 ]\n",
      "tstep [-0.00246196  0.00343338  0.00718721  0.00787102  0.00031738  0.00031678\n",
      "  0.00031582  0.00031639]\n",
      "obj: 6.105035856367548\n",
      "x [-0.09054046 -5.90543154  0.17881921  0.17820277  0.05979639  0.05976831\n",
      "  0.05972313  0.05974999]\n",
      "tstep [-0.00221042  0.00423005  0.00658169  0.00710236  0.0002626   0.00026209\n",
      "  0.00026127  0.00026176]\n",
      "obj: 6.10330277780941\n",
      "x [-0.09275088 -5.9012015   0.1854009   0.18530513  0.06005898  0.0600304\n",
      "  0.0599844   0.06001175]\n",
      "tstep [-0.00228691  0.00316465  0.00689287  0.00737262  0.00025685  0.00025633\n",
      "  0.0002555   0.00025599]\n",
      "obj: 6.101807553065499\n",
      "x [-0.09503779 -5.89803684  0.19229376  0.19267775  0.06031584  0.06028673\n",
      "  0.0602399   0.06026774]\n",
      "tstep [-0.00204813  0.00397502  0.00626559  0.00663056  0.00021341  0.00021296\n",
      "  0.00021226  0.00021268]\n",
      "obj: 6.100252710250015\n",
      "x [-0.09708592 -5.89406182  0.19855936  0.19930831  0.06052924  0.06049969\n",
      "  0.06045216  0.06048042]\n",
      "tstep [-0.00215173  0.00295899  0.00664188  0.00698456  0.00021335  0.00021288\n",
      "  0.00021215  0.00021258]\n",
      "obj: 6.0988999191584625\n",
      "x [-0.09923765 -5.89110283  0.20520124  0.20629286  0.06074259  0.06071258\n",
      "  0.06066431  0.060693  ]\n",
      "tstep [-0.00192097  0.00377342  0.00599859  0.00625752  0.00017771  0.00017732\n",
      "  0.0001767   0.00017707]\n",
      "obj: 6.0974810491731954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.10115862, -5.88732941,  0.21119983,  0.21255039,  0.0609203 ,\n",
       "        0.06088989,  0.06084101,  0.06087007])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "newton_optimization(KL_obj_bar,KL_grad_bar, KL_hessian_bar, x0,0.01, tol=1e-6, max_iter=20, alfa=0.4, beta=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "05e38616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.86789220e+00,  3.58733854e-07, -8.91981024e-01, -2.78433489e+00,\n",
       "       -1.57907406e+00])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/alpha*(x_s2[0]-X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
